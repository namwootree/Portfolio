{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poly encoder training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPq4FZFavC2KRYf9B5WU60A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/Retrieval-Based-Chatbot/blob/main/poly_encoder_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 104tDaWyepf1scqrMA7m-ZNCkBV7QyUoi\n",
        "!gdown 1z538R6gjDhrpziV1dVv4SgRvP_7rcfnV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBh2m7nZL8qP",
        "outputId": "dc2fe5d9-4388-4fd4-aaf1-06d4df2fd6be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=104tDaWyepf1scqrMA7m-ZNCkBV7QyUoi\n",
            "To: /content/train.csv\n",
            "100% 803k/803k [00:00<00:00, 151MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z538R6gjDhrpziV1dVv4SgRvP_7rcfnV\n",
            "To: /content/dev.csv\n",
            "100% 76.1k/76.1k [00:00<00:00, 79.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Poly-Encoder"
      ],
      "metadata": {
        "id": "DAEDgVE13tmn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXufVK0iRN3Z",
        "outputId": "e87995e1-bf0b-41e3-c2d8-626fda1782c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEJHV_6YR4k",
        "outputId": "a34a706c-6c40-4d76-8591-ae0630ead1bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul  4 12:38:32 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets folium==0.2.1 apex"
      ],
      "metadata": {
        "id": "pAcEd4LC1XkQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lrYnocYNH4",
        "outputId": "5ee2ade3-40ed-4ee4-d8e1-bf6f64a409ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Poly-Encoder'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 93 (delta 18), reused 15 (delta 6), pack-reused 57\u001b[K\n",
            "Unpacking objects: 100% (93/93), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dotsnangles/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Poly-Encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWr7HVEMMA2i",
        "outputId": "1b13052f-38c8-4de1-e928-f3326af46055"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, BertPreTrainedModel, BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import argparse\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, BertPreTrainedModel, BertModel, BertConfig, BertTokenizer, BertTokenizerFast\n",
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from dataset import SelectionDataset\n",
        "from transform import SelectionSequentialTransform, SelectionJoinTransform, SelectionConcatTransform\n",
        "from encoder import PolyEncoder, BiEncoder, CrossEncoder\n",
        "\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "\n",
        "import logging"
      ],
      "metadata": {
        "id": "GhKdojJmGUPQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown --folder 1uC1pSCrh9xlieF60z78QuCg7OxvU9kUs\n",
        "# !mv /content/dstc7/*.json /content/Poly-Encoder/dstc7\n",
        "# !mv /content/dstc7/*.tsv /content/Poly-Encoder/dstc7"
      ],
      "metadata": {
        "id": "edrW8JmxZWrb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Poly-Encoder/dstc7\n",
        "# !bash parse.sh\n",
        "# %cd /content"
      ],
      "metadata": {
        "id": "vGQaVPejhcsG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = 'klue/bert-base'"
      ],
      "metadata": {
        "id": "WheELxD_B2ly"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_config = BertConfig.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "yx0TP1yh2Q1Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert = BertModel.from_pretrained(model_name, config=bert_config)\n",
        "# tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "33cqB6o7_f3L"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Poly-Encoder"
      ],
      "metadata": {
        "id": "Hghi8P7p1qzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099755a7-bb23-4477-e008-7e19f50c4435"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "def eval_running_model(dataloader, test=False):\n",
        "    model.eval()\n",
        "    eval_loss, eval_hit_times = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # r10 = r2 = r1 = r5 = 0\n",
        "    # mrr = []\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        if args.architecture == 'cross':\n",
        "            text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch, labels_batch = batch\n",
        "            with torch.no_grad():\n",
        "                logits = model(text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch)\n",
        "                loss = F.cross_entropy(logits, torch.argmax(labels_batch, 1))\n",
        "        else:\n",
        "            context_token_ids_list_batch, context_input_masks_list_batch, \\\n",
        "            response_token_ids_list_batch, response_input_masks_list_batch, labels_batch = batch\n",
        "            with torch.no_grad():\n",
        "                logits = model(context_token_ids_list_batch, context_input_masks_list_batch,\n",
        "                                              response_token_ids_list_batch, response_input_masks_list_batch)\n",
        "                loss = F.cross_entropy(logits, torch.argmax(labels_batch, 1))\n",
        "        # r2_indices = torch.topk(logits, 2)[1] # R 2 @ 100\n",
        "        # r5_indices = torch.topk(logits, 5)[1] # R 5 @ 100\n",
        "        # r10_indices = torch.topk(logits, 10)[1] # R 10 @ 100\n",
        "        # r1 += (logits.argmax(-1) == 0).sum().item()\n",
        "        # r2 += ((r2_indices==0).sum(-1)).sum().item()\n",
        "        # r5 += ((r5_indices==0).sum(-1)).sum().item()\n",
        "        # r10 += ((r10_indices==0).sum(-1)).sum().item()\n",
        "        # # mrr\n",
        "        # logits = logits.data.cpu().numpy()\n",
        "        # for logit in logits:\n",
        "        #     y_true = np.zeros(len(logit))\n",
        "        #     y_true[0] = 1\n",
        "        #     mrr.append(label_ranking_average_precision_score([y_true], [logit]))\n",
        "        eval_loss += loss.item()\n",
        "        nb_eval_examples += labels_batch.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    # eval_accuracy = r1 / nb_eval_examples\n",
        "    if not test:\n",
        "        result = {\n",
        "            'train_loss': tr_loss / nb_tr_steps,\n",
        "            'eval_loss': eval_loss,\n",
        "            # 'R1': r1 / nb_eval_examples,\n",
        "            # 'R2': r2 / nb_eval_examples,\n",
        "            # 'R5': r5 / nb_eval_examples,\n",
        "            # 'R10': r10 / nb_eval_examples,\n",
        "            # 'MRR': np.mean(mrr),\n",
        "            'epoch': epoch,\n",
        "            'global_step': global_step,\n",
        "        }\n",
        "    else:\n",
        "        result = {\n",
        "            'eval_loss': eval_loss,\n",
        "            # 'R1': r1 / nb_eval_examples,\n",
        "            # 'R2': r2 / nb_eval_examples,\n",
        "            # 'R5': r5 / nb_eval_examples,\n",
        "            # 'R10': r10 / nb_eval_examples,\n",
        "            # 'MRR': np.mean(mrr),\n",
        "        }\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "CtaB4Qhz4ps7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "        \"bert_model\": 'klue/bert-base',\n",
        "        \"eval\": False,\n",
        "        \"model_type\": 'bert',\n",
        "        \"output_dir\": 'output_dstc7/',\n",
        "        \"train_dir\": '/content/',\n",
        "\n",
        "        \"use_pretrain\": True,\n",
        "        \"architecture\": 'poly',\n",
        "\n",
        "        \"max_contexts_length\": 128,\n",
        "        \"max_response_length\": 32,\n",
        "        \"train_batch_size\": 1,\n",
        "        \"eval_batch_size\": 1,\n",
        "        \"print_freq\": 100,\n",
        "\n",
        "        \"poly_m\": 16,\n",
        "\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_steps\": 100,\n",
        "        \"adam_epsilon\": 1e-8,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "\n",
        "        \"num_train_epochs\": 10.0,\n",
        "        'seed': 12345,\n",
        "        'gradient_accumulation_steps': 1,\n",
        "        \"fp16\": False,\n",
        "        \"fp16_opt_level\": \"O1\",\n",
        "        'gpu': 0\n",
        "        }"
      ],
      "metadata": {
        "id": "jKhi-3lB4tvY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from easydict import EasyDict as edict\n",
        "args = edict(args)"
      ],
      "metadata": {
        "id": "CLTdqAqq7BZJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"%d\" % args.gpu\n",
        "set_seed(args)\n",
        "\n",
        "## init dataset and bert model\n",
        "model_name = 'klue/bert-base'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "context_transform = SelectionJoinTransform(tokenizer=tokenizer, max_len=args.max_contexts_length)\n",
        "response_transform = SelectionSequentialTransform(tokenizer=tokenizer, max_len=args.max_response_length)\n",
        "concat_transform = SelectionConcatTransform(tokenizer=tokenizer, max_len=args.max_response_length+args.max_contexts_length)\n",
        "\n",
        "print('=' * 80)\n",
        "print('Train dir:', args.train_dir)\n",
        "print('Output dir:', args.output_dir)\n",
        "print('=' * 80)\n",
        "\n",
        "if not args.eval:\n",
        "    train_dataset = SelectionDataset(os.path.join(args.train_dir, 'train.csv'),\n",
        "                                                                    context_transform, response_transform, concat_transform, sample_cnt=None, mode=args.architecture)\n",
        "    val_dataset = SelectionDataset(os.path.join(args.train_dir, 'dev.csv'),\n",
        "                                                                context_transform, response_transform, concat_transform, sample_cnt=None, mode=args.architecture)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=args.train_batch_size, collate_fn=train_dataset.batchify_join_str, shuffle=True, num_workers=0)\n",
        "    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "else: # test\n",
        "    val_dataset = SelectionDataset(os.path.join(args.train_dir, 'test.txt'),\n",
        "                                                                context_transform, response_transform, concat_transform, sample_cnt=None, mode=args.architecture)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=args.eval_batch_size, collate_fn=val_dataset.batchify_join_str, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "epoch_start = 1\n",
        "global_step = 0\n",
        "best_eval_loss = float('inf')\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)\n",
        "\n",
        "log_wf = open(os.path.join(args.output_dir, 'log.txt'), 'a', encoding='utf-8')\n",
        "print(args, file=log_wf)\n",
        "\n",
        "state_save_path = os.path.join(args.output_dir, '{}_{}_pytorch_model.bin'.format(args.architecture, args.poly_m))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "########################################\n",
        "## build BERT encoder\n",
        "########################################\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(model_name)\n",
        "\n",
        "bert = BertModel.from_pretrained(model_name, config=bert_config)\n",
        "\n",
        "model = PolyEncoder(bert_config, bert=bert, poly_m=args.poly_m)\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.to(device)\n",
        "\n",
        "if args.eval:\n",
        "    print('Loading parameters from', state_save_path)\n",
        "    model.load_state_dict(torch.load(state_save_path))\n",
        "    test_result = eval_running_model(val_dataloader, test=True)\n",
        "    print (test_result)\n",
        "    exit()\n",
        "\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": args.weight_decay,\n",
        "    },\n",
        "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        ")\n",
        "if args.fp16:\n",
        "    try:\n",
        "        from apex import amp\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "    model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "print_freq = args.print_freq//args.gradient_accumulation_steps\n",
        "eval_freq = min(len(train_dataloader) // 2, 1000)\n",
        "eval_freq = eval_freq//args.gradient_accumulation_steps\n",
        "print('Print freq:', print_freq, \"Eval freq:\", eval_freq)\n",
        "\n",
        "for epoch in range(epoch_start, int(args.num_train_epochs) + 1):\n",
        "    tr_loss = 0\n",
        "    nb_tr_steps = 0\n",
        "    with tqdm(total=len(train_dataloader)//args.gradient_accumulation_steps) as bar:\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            if args.architecture == 'cross':\n",
        "                text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch, labels_batch = batch\n",
        "                loss = model(text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch, labels_batch)\n",
        "            else:\n",
        "                context_token_ids_list_batch, context_input_masks_list_batch, \\\n",
        "                response_token_ids_list_batch, response_input_masks_list_batch, labels_batch = batch\n",
        "                loss = model(context_token_ids_list_batch, context_input_masks_list_batch,\n",
        "                                        response_token_ids_list_batch, response_input_masks_list_batch,\n",
        "                                        labels_batch)\n",
        "\n",
        "            loss = loss / args.gradient_accumulation_steps\n",
        "            \n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "            \n",
        "            tr_loss += loss.item()\n",
        "\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                nb_tr_steps += 1\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if nb_tr_steps and nb_tr_steps % print_freq == 0:\n",
        "                    bar.update(min(print_freq, nb_tr_steps))\n",
        "                    time.sleep(0.02)\n",
        "                    print(global_step, tr_loss / nb_tr_steps)\n",
        "                    log_wf.write('%d\\t%f\\n' % (global_step, tr_loss / nb_tr_steps))\n",
        "\n",
        "                if global_step and global_step % eval_freq == 0:\n",
        "                    val_result = eval_running_model(val_dataloader)\n",
        "                    print('Global Step %d VAL res:\\n' % global_step, val_result)\n",
        "                    log_wf.write('Global Step %d VAL res:\\n' % global_step)\n",
        "                    log_wf.write(str(val_result) + '\\n')\n",
        "\n",
        "                    if val_result['eval_loss'] < best_eval_loss:\n",
        "                        best_eval_loss = val_result['eval_loss']\n",
        "                        val_result['best_eval_loss'] = best_eval_loss\n",
        "                        # save model\n",
        "                        print('[Saving at]', state_save_path)\n",
        "                        log_wf.write('[Saving at] %s\\n' % state_save_path)\n",
        "                        torch.save(model.state_dict(), state_save_path)\n",
        "\n",
        "            log_wf.flush()\n",
        "\n",
        "    # add a eval step after each epoch\n",
        "    val_result = eval_running_model(val_dataloader)\n",
        "    print('Epoch %d, Global Step %d VAL res:\\n' % (epoch, global_step), val_result)\n",
        "    log_wf.write('Global Step %d VAL res:\\n' % global_step)\n",
        "    log_wf.write(str(val_result) + '\\n')\n",
        "\n",
        "    if val_result['eval_loss'] < best_eval_loss:\n",
        "        best_eval_loss = val_result['eval_loss']\n",
        "        val_result['best_eval_loss'] = best_eval_loss\n",
        "        # save model\n",
        "        print('[Saving at]', state_save_path)\n",
        "        log_wf.write('[Saving at] %s\\n' % state_save_path)\n",
        "        torch.save(model.state_dict(), state_save_path)\n",
        "    print(global_step, tr_loss / nb_tr_steps)\n",
        "    log_wf.write('%d\\t%f\\n' % (global_step, tr_loss / nb_tr_steps))"
      ],
      "metadata": {
        "id": "jgSd5pJL4Swz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3778b73f-2fd0-4b77-f19d-6d9392856c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Train dir: /content/\n",
            "Output dir: output_dstc7/\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print freq: 100 Eval freq: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 100/10823 [00:11<21:06,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 200/10823 [00:23<20:50,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 300/10823 [00:35<20:38,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 400/10823 [00:47<20:26,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 500/10823 [00:58<20:14,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 600/10823 [01:10<20:02,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 700/10823 [01:22<19:47,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "700 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 800/10823 [01:33<19:35,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 900/10823 [01:45<19:23,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 1000/10823 [01:57<19:10,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 0.0\n",
            "Global Step 1000 VAL res:\n",
            " {'train_loss': 0.0, 'eval_loss': 0.0, 'epoch': 1, 'global_step': 1000}\n",
            "[Saving at] output_dstc7/poly_16_pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1100/10823 [02:34<31:36,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1100 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 1200/10823 [02:46<27:28,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 1300/10823 [02:57<24:33,  6.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1300 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 1400/10823 [03:09<22:28,  6.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 1500/10823 [03:21<21:00,  7.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 1600/10823 [03:32<19:55,  7.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 1700/10823 [03:44<19:06,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1700 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 1800/10823 [03:56<18:31,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1800 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 1900/10823 [04:08<18:05,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1900 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 2000/10823 [04:19<17:40,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000 0.0\n",
            "Global Step 2000 VAL res:\n",
            " {'train_loss': 0.0, 'eval_loss': 0.0, 'epoch': 1, 'global_step': 2000}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 2100/10823 [04:56<28:10,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2100 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2200/10823 [05:07<24:31,  5.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2200 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 2300/10823 [05:19<21:57,  6.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2300 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 2400/10823 [05:31<20:07,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2400 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 2500/10823 [05:43<18:45,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 2600/10823 [05:54<17:48,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2600 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 2700/10823 [06:06<17:01,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2700 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 2800/10823 [06:18<16:27,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2800 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 2900/10823 [06:29<15:58,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2900 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 3000/10823 [06:41<15:35,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000 0.0\n",
            "Global Step 3000 VAL res:\n",
            " {'train_loss': 0.0, 'eval_loss': 0.0, 'epoch': 1, 'global_step': 3000}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 3100/10823 [07:17<24:45,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3100 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PolyEncoder(BertPreTrainedModel):\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super().__init__(config, *inputs, **kwargs)\n",
        "        self.bert = kwargs['bert']\n",
        "        self.poly_m = kwargs['poly_m']\n",
        "        self.poly_code_embeddings = nn.Embedding(self.poly_m, config.hidden_size)\n",
        "        # https://github.com/facebookresearch/ParlAI/blob/master/parlai/agents/transformer/polyencoder.py#L355\n",
        "        torch.nn.init.normal_(self.poly_code_embeddings.weight, config.hidden_size ** -0.5)\n",
        "\n",
        "    def dot_attention(self, q, k, v):\n",
        "        # q: [bs, poly_m, dim] or [bs, res_cnt, dim]\n",
        "        # k=v: [bs, length, dim] or [bs, poly_m, dim]\n",
        "        attn_weights = torch.matmul(q, k.transpose(2, 1)) # [bs, poly_m, length]\n",
        "        attn_weights = F.softmax(attn_weights, -1)\n",
        "        output = torch.matmul(attn_weights, v) # [bs, poly_m, dim]\n",
        "        return output\n",
        "\n",
        "    def forward(self, context_input_ids, context_input_masks,\n",
        "                            responses_input_ids, responses_input_masks, labels=None, emb_sample=None):\n",
        "        # during training, only select the first response\n",
        "        # we are using other instances in a batch as negative examples\n",
        "        if labels is not None:\n",
        "            responses_input_ids = responses_input_ids[:, 0, :].unsqueeze(1)\n",
        "            responses_input_masks = responses_input_masks[:, 0, :].unsqueeze(1)\n",
        "        batch_size, res_cnt, seq_length = responses_input_ids.shape # res_cnt is 1 during training\n",
        "\n",
        "        # context encoder\n",
        "        ctx_out = self.bert(context_input_ids, context_input_masks)[0]  # [bs, length, dim]\n",
        "        poly_code_ids = torch.arange(self.poly_m, dtype=torch.long).to(context_input_ids.device)\n",
        "        poly_code_ids = poly_code_ids.unsqueeze(0).expand(batch_size, self.poly_m)\n",
        "        poly_codes = self.poly_code_embeddings(poly_code_ids) # [bs, poly_m, dim]\n",
        "        embs = self.dot_attention(poly_codes, ctx_out, ctx_out) # [bs, poly_m, dim]\n",
        "\n",
        "        # response encoder\n",
        "        responses_input_ids = responses_input_ids.view(-1, seq_length)\n",
        "        responses_input_masks = responses_input_masks.view(-1, seq_length)\n",
        "        cand_emb = self.bert(responses_input_ids, responses_input_masks)[0][:,0,:] # [bs, dim]\n",
        "        cand_emb = cand_emb.view(batch_size, res_cnt, -1) # [bs, res_cnt, dim]\n",
        "\n",
        "        # merge\n",
        "        if labels is not None:\n",
        "            # we are recycling responses for faster training\n",
        "            # we repeat responses for batch_size times to simulate test phase\n",
        "            # so that every context is paired with batch_size responses\n",
        "            cand_emb = cand_emb.permute(1, 0, 2) # [1, bs, dim]\n",
        "            cand_emb = cand_emb.expand(batch_size, batch_size, cand_emb.shape[2]) # [bs, bs, dim]\n",
        "            ctx_emb = self.dot_attention(cand_emb, embs, embs).squeeze() # [bs, bs, dim]\n",
        "            dot_product = (ctx_emb*cand_emb).sum(-1) # [bs, bs]\n",
        "            mask = torch.eye(batch_size).to(context_input_ids.device) # [bs, bs]\n",
        "            loss = F.log_softmax(dot_product, dim=-1) * mask\n",
        "            loss = (-loss.sum(dim=1)).mean()\n",
        "            return loss\n",
        "\n",
        "        # from DB\n",
        "        elif emb_sample is not None:\n",
        "\n",
        "            cand_emb = emb_sample[0][:,0,:] # [bs, dim]\n",
        "            cand_emb = cand_emb.view(batch_size, res_cnt, -1) # [bs, res_cnt, dim]\n",
        "            ctx_emb = self.dot_attention(cand_emb, embs, embs) # [bs, res_cnt, dim]\n",
        "            dot_product = (ctx_emb*cand_emb).sum(-1)\n",
        "            return dot_product\n",
        "\n",
        "        else:\n",
        "            ctx_emb = self.dot_attention(cand_emb, embs, embs) # [bs, res_cnt, dim]\n",
        "            dot_product = (ctx_emb*cand_emb).sum(-1)\n",
        "            return dot_product\n",
        "\n",
        "    def creat_emb(self, input_id, input_mask):\n",
        "        "
      ],
      "metadata": {
        "id": "J9Tz0BS2-IGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "se6dVwoABgLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M3d9RLwBXr0",
        "outputId": "f5333c87-2c33-43fb-fcbb-5343dc47666a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(32001, 768)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}
