{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/Retrieval-Based-Chatbot/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HXPA7-uDAIHP"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/Poly-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXufVK0iRN3Z",
        "outputId": "98f04741-13eb-4984-964e-142694b2ab2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEJHV_6YR4k",
        "outputId": "b781cafb-99ad-487b-f35f-3b6754b3bc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul  7 01:02:34 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n-ZyBZPWfX5m"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets folium==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lrYnocYNH4",
        "outputId": "03c9230e-6539-4f73-e297-0f886b1f1193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Poly-Encoder'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 129 (delta 41), reused 20 (delta 8), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (129/129), 40.70 KiB | 10.17 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dotsnangles/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LzRLhnM-stL",
        "outputId": "b2a51d24-d66b-470f-b56d-c60f09bbd062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Poly-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AcEZq-UQ-prG"
      },
      "outputs": [],
      "source": [
        "!gdown -q --folder 1Ipr-aNF5ELMY0HTXAmeV26LlgktKUfmG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "psjYArLBO1-C"
      },
      "outputs": [],
      "source": [
        "# \"--bert_model\", default='ckpt/pretrained/bert-small-uncased', type=str\n",
        "# \"--eval\", action=\"store_true\"\n",
        "# \"--model_type\", default='bert', type=str\n",
        "# \"--output_dir\", required=True, type=str\n",
        "# \"--train_dir\", default='data/ubuntu_data', type=str\n",
        "# \"--train_file\", default='data/ubuntu_data', type=str\n",
        "# \"--dev_file\", default='data/ubuntu_data', type=str\n",
        "# \"--test_file\", default='data/ubuntu_data', type=str\n",
        "\n",
        "# \"--use_pretrain\", action=\"store_true\"\n",
        "# \"--architecture\", required=True, type=str, help='[poly, bi, cross]'\n",
        "\n",
        "# \"--max_contexts_length\", default=128, type=int\n",
        "# \"--max_response_length\", default=32, type=int\n",
        "# \"--train_batch_size\", default=32, type=int, help=\"Total batch size for training.\"\n",
        "# \"--eval_batch_size\", default=32, type=int, help=\"Total batch size for eval.\"\n",
        "# \"--print_freq\", default=100, type=int, help=\"Log frequency\"\n",
        "\n",
        "# \"--poly_m\", default=0, type=int, help=\"Number of m of polyencoder\"\n",
        "\n",
        "# \"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\"\n",
        "# \"--weight_decay\", default=0.01, type=float\n",
        "# \"--warmup_steps\", default=100, type=float\n",
        "# \"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\"\n",
        "# \"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\"\n",
        "\n",
        "# \"--num_train_epochs\", default=10.0, type=float, help=\"Total number of training epochs to perform.\"\n",
        "# '--seed', type=int, default=12345, help=\"random seed for initialization\"\n",
        "# '--gradient_accumulation_steps', type=int, default=1, help=\"Number of updates steps to accumulate before performing a backward/update pass.\"\n",
        "\n",
        "# \"--fp16\", action=\"store_true\", help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"\n",
        "\n",
        "# \"--fp16_opt_level\", type=str, default=\"O1\", help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\" \"See details at https://nvidia.github.io/apex/amp.html\"\n",
        "# '--gpu', type=int, default=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 run.py \\\n",
        "# \\\n",
        "# --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' \\\n",
        "# --train_dir '감성대화챗봇데이터/' \\\n",
        "# --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' \\\n",
        "# --architecture poly --poly_m 16 \\\n",
        "# \\\n",
        "# --num_train_epochs 10 \\\n",
        "# \\\n",
        "# --train_batch_size 4 \\\n",
        "# --eval_batch_size 4 \\\n",
        "# --gradient_accumulation_steps 1 \\\n",
        "# \\\n",
        "# --print_freq 200 \\ \n",
        "# \\\n",
        "# --max_contexts_length 256 --max_response_length 128"
      ],
      "metadata": {
        "id": "mqEuPskv5T1y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch5QnDV6jVZj",
        "outputId": "9b04a1c4-7adf-4eba-900b-3b8095c080b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(adam_epsilon=1e-08, architecture='poly', bert_model='klue/bert-base', dev_file='val_data_source.pickle', eval=False, eval_batch_size=4, fp16=False, fp16_opt_level='O1', gpu=0, gradient_accumulation_steps=1, learning_rate=5e-05, max_contexts_length=256, max_grad_norm=1.0, max_response_length=128, model_type='bert', num_train_epochs=10.0, output_dir='chatbot_output/', poly_m=16, print_freq=200, seed=12345, test_file='test_data_source.pickle', train_batch_size=4, train_dir='감성대화챗봇데이터/', train_file='train_data_source.pickle', use_pretrain=False, warmup_steps=100, weight_decay=0.01)\n",
            "================================================================================\n",
            "Train dir: 감성대화챗봇데이터/\n",
            "Output dir: chatbot_output/\n",
            "================================================================================\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Print freq: 200 Eval freq: 1000\n",
            "  2% 200/10220 [00:40<33:36,  4.97it/s]200 3.566680881452029\n",
            "  4% 400/10220 [01:20<32:57,  4.96it/s]400 2.4550624050942336\n",
            "  6% 600/10220 [02:00<32:17,  4.97it/s]600 2.004398601180163\n",
            "  8% 800/10220 [02:41<31:36,  4.97it/s]800 1.8043795053215155\n",
            " 10% 1000/10220 [03:21<30:55,  4.97it/s]1000 1.6533432422512213\n",
            " 10% 1000/10220 [05:34<51:23,  2.99it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 301, in <module>\n",
            "    val_result = eval_running_model(val_dataloader)\n",
            "  File \"run.py\", line 56, in eval_running_model\n",
            "    r1 += (logits.argmax(-1) == 0).sum().item()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --architecture poly --poly_m 16 --num_train_epochs 10 --train_batch_size 4 --eval_batch_size 4 --gradient_accumulation_steps 1 --print_freq 200 --max_contexts_length 256 --max_response_length 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POq7e5BjjXSr"
      },
      "outputs": [],
      "source": [
        "# !python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' --architecture poly --poly_m 16 --eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Qdur4wRAhb"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/Poly-Encoder/output_dstc7 '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--6Br9QFwy3N"
      },
      "outputs": [],
      "source": [
        "# PATH = '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder/output_dstc7'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 검증"
      ],
      "metadata": {
        "id": "eI9iOlJMqnsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('감성대화챗봇데이터/train_data_source.pickle', 'rb') as f:\n",
        "    train = pickle.load(f)\n",
        "with open('감성대화챗봇데이터/val_data_source.pickle', 'rb') as f:\n",
        "    dev = pickle.load(f)"
      ],
      "metadata": {
        "id": "vVRqi7D4Z9cO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 500"
      ],
      "metadata": {
        "id": "-Mss6BMYhtHR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[index]['context']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUXvHneNa2Y9",
        "outputId": "52e241ec-aa09-4f53-92c6-2ca91f11f09b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['participant 1: 이번에 상사가 큰 실수를 저질렀어. 너무 당황스러워.',\n",
              " 'participant 2: 상사의 실수 때문에 당황스러우시군요.',\n",
              " 'participant 1: 매번 팀원들에게 일을 떠넘기기만 하더니 결국 일을 저질렀네.',\n",
              " 'participant 2: 상사가 일을 떠넘기다가 실수를 했다고 생각하시는군요. 당황한 마음이 조금이라도 진정되려면 어떻게 해야 좋을까요?',\n",
              " 'participant 1: 나는 조용히 있어야지. 나섰다가 더 큰일이 나면 어떡해.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[index]['responses']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGzO7GhBhoZh",
        "outputId": "24bd3859-bad4-4fc5-abee-2e655d4c4dd5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['큰일이 나지 않게 가만히 있으려고 하시는군요.',\n",
              " '흰옷을 입고 결혼식장에 갈까 하는 생각까지도 드셨나 보네요.',\n",
              " '요양원 사람들과 잘 어울려서 부정적인 감정은 잊어버리실 수 있길 바라요.',\n",
              " '언니와의 연락을 통해 언니의 걱정하는 마음이 조금이나마 덜어지길 바랄게요.',\n",
              " '피해다니시는 것이 상책이라 생각하시는 군요.',\n",
              " '어떤 걸 먹을 생각이신가요?',\n",
              " '초심으로 돌아가기로 하셨군요. 일에 전념하여 지금의 기분이 나아지셨으면 좋겠어요.',\n",
              " '아들과 대화를 통해 결정을 내리려 하시는군요.',\n",
              " '자신의 심정을 부모님께 이야기할까 고려 중이군요.',\n",
              " '아내에 대한 사랑으로 잘 극복해 나가길 바라요.',\n",
              " '그렇군요. 오늘 좋은 외국인 친구를 만들기 바라요.',\n",
              " '주변의 도움으로 좋은 방법을 얻을 수 있길 바라요.',\n",
              " '체력이 증진되어 꾸준히 운동한 보람을 느끼시는군요.',\n",
              " '힘든 상황을 정면으로 돌파하실 생각이시군요.',\n",
              " '야근하지 않아도 되게끔 업무가 원만히 해결되길 바랍니다.',\n",
              " '성적으로 차별하시는 어머니께 혐오스러운 마음이 드시는 군요.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev[index]['context']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HFg-Z4ca_RS",
        "outputId": "191eabb1-fb60-4edf-ee5b-4cc5dc1acf10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['participant 1: 이번 시험은 쉬워서 마음이 편해.',\n",
              " 'participant 2: 걱정이 적어지셨겠어요. 이제 무엇을 하실 건가요?',\n",
              " 'participant 1: 내일도 시험이니까 열심히 공부할래.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev[index]['responses']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qZBxsx2hhVz",
        "outputId": "dc37c1bf-1dd8-43a8-96e1-63b15726beba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['좋아요. 내일 시험도 좋은 결과가 있기를 바랄게요.',\n",
              " '엄마와의 대화에서 힌트를 얻었으면 좋겠네요.',\n",
              " '당분간 휴식을 취하면서 원하는 바를 이루시길 바라요.',\n",
              " '가족 관계 문제로 많이 불안하시겠네요.',\n",
              " '아내와의 접촉을 줄여서 관계가 회복되길 바라요.',\n",
              " '경제적인 문제가 많이 나아졌으면 좋겠어요.',\n",
              " '동생에게도 영어를 가르쳐주려고 하시는군요.',\n",
              " '주변 지인들에게 도움을 청하려고 하시는군요. 원하시는대로 상황이 나아지길 바랄게요.',\n",
              " '친구 분들과의 대화로 영양제 문제가 해결되었으면 좋겠네요.',\n",
              " '마음에 드는 좋은 아르바이트를 찾았으면 좋겠어요.',\n",
              " '면역력을 높일 수 있는 운동을 많이 하시는군요.',\n",
              " '준비하신 만큼 좋은 결과가 있기를 바라요.',\n",
              " '직업상담을 받으시는군요. 도움이 되길 바라요.',\n",
              " '형편이 안 좋아서 병원에 못 가는 일은 없었으면 좋겠다고 생각하시는군요.',\n",
              " '가족에게 다이어트 얘기를 들어서 기분이 언짢으시군요.',\n",
              " '더 좋은 기회를 위한 발판으로 생각해보시는건 어떠세요?',\n",
              " '사춘기가 지나면 다시 모녀지간이 가까워지길 소망합니다.',\n",
              " '좋아하는 팝송을 들으며 영어 단어 학습이 잘 되길 바랄게요.',\n",
              " '좌절감을 주는 대인관계와 거기서 오는 실망감으로 괴로우시군요.',\n",
              " '건강하시길 바라요.',\n",
              " '목표가 있고 배려심이 깊은 사람이 이상형이시군요.',\n",
              " '스스로의 선택을 후회하지 않으시는 것 같아요.',\n",
              " '직장상사와 친해지시면 좋겠네요.',\n",
              " '고양이는 사랑스러운 동물이죠.',\n",
              " '네. 더욱더 건강해지시길 기원합니다.',\n",
              " '도시락을 맘대로 뺏어 먹지 않도록 단호하게 말하려 하시는군요.',\n",
              " '건강검진을 받으려 하시는군요.',\n",
              " '건강 문제로 걱정이 많으시군요.',\n",
              " '좋은 방법이에요. 잘 극복하길 바라요.',\n",
              " '친한 친구와의 진솔한 대화로 상황이 개선되길 바랄게요.',\n",
              " '그렇군요. 너무 안타까워요.',\n",
              " '주변 사람들과 대화로 상황이 나아졌으면 좋겠어요.',\n",
              " '기억이 나지 않아서 많이 당황스러우시겠어요.',\n",
              " '친구의 눈물 흘리는 모습에 슬프셨군요.',\n",
              " '개인과외를 받아서 진도도 따라잡고 불안함도 사라지길 바라요.',\n",
              " '행복한 유럽여행이 되셨으면 좋겠어요.',\n",
              " '앞으로 어떻게 하실 생각이세요?',\n",
              " '여러모로 생각이 많으시겠어요.',\n",
              " '성공적인 보고서 작성으로 팀장님께 칭찬받을 수 있으면 좋겠어요.',\n",
              " '아내를 먼저 생각해 치료비를 빌려서라도 마련하려 하시는군요.',\n",
              " '아내분과의 대화로 상황이 나아지기를 바랄게요.',\n",
              " '선생님한테 얘기해 보셔서 슬픈 마음이 사라지시면 좋겠어요.',\n",
              " '증거 자료를 통해 꼭 노동의 대가를 받아 병도 완치하고 행복해지길 바라요.',\n",
              " '두 분이서 얘기해 보시고 생각한 대로 일이 잘 해결되었으면 좋겠어요.',\n",
              " '마음을 차근차근하다보면 즐거운 시간을 보낼 수 있을 거예요. 힘내세요.',\n",
              " '친구들에게 맛있는 음식을 대접하고 기분도 좋아지면 좋겠어요.',\n",
              " '친구들과 놀며 기분이 좋아지면 좋겠어요.',\n",
              " '투자가 성공해서 재정에 대한 불안감이 줄어들기를 바랄게요.',\n",
              " '매번 면접에서 떨어져서 낙담하게 되었군요.',\n",
              " '다행이네요. 빨라 발견한 거라 위안하시고 치료 잘 받으셔요.',\n",
              " '내 모습을 그대로 받아드리실 생각이시군요.',\n",
              " '병원에 얘기해서 문제가 해결되었으면 좋겠네요.',\n",
              " '전화하고 기분이 풀리셨으면 좋겠어요. 잘 해결되길 바라요.',\n",
              " '말씀하신 것처럼 규칙전인 식습관과 운동을 더해서 소화불량 증세가 완쾌되길 바라요.',\n",
              " '문제를 직접 이야기하는 방법을 선택하셨군요.',\n",
              " '빨리 경제적으로 독립하기로 결정하셨군요. 얼른 독립할 수 있기를 기원할게요.',\n",
              " '승진 기준을 확인하셔서 상황이 잘 해결되었으면 좋겠어요.',\n",
              " '의료보험 적용이 안되어 많이 놀라셨겠어요.',\n",
              " '난처한 상황이 생기질 않길 바라요.',\n",
              " '하루빨리 가장 최선의 방법을 찾으시길 바라요.',\n",
              " '좋은 대처 방법을 생각해 내시길 바라요.',\n",
              " '노후의 재정상태에 대해 고민하느라 힘겨우신 것 같아요.',\n",
              " '동사무소에서 계획했던 대로 일이 잘 풀리시기를 바라요.',\n",
              " '차분하게 생각하고 다음 면접을 기다리고 계시는군요.',\n",
              " '친구들과의 우정 오래되도록 바랄게요.',\n",
              " '어떻게 하면 고민을 나눌 상대를 찾을 수 있을까요?',\n",
              " '가족들과의 외출로 기분이 좀 나아지셨으면 좋겠어요.',\n",
              " '다른 회사로 이직을 잘 준비하셔서 좋은 곳으로 이직하셨으면 좋겠어요.',\n",
              " '이야기가 잘 되었으면 좋겠어요.',\n",
              " '추억을 많이 쌓아서 더욱 우정이 돈독해 지면 좋겠어요.',\n",
              " '아들과 대화가 잘 되었으면 좋겠어요.',\n",
              " '주변 지인을 통해 손자 걱정이 잘 해결됐으면 좋겠어요.',\n",
              " '새로운 곳에서 새롭게 시작하고 싶으시군요.',\n",
              " '부모님께서 바쁘셔서 못 가게 되었군요. 속상하시겠어요.',\n",
              " '저런 구역질이 나려고 하는군요. 혹시 전날에 어떤 음식을 드셨나요?',\n",
              " '취미 생활을 하면서 기분이 풀리셨으면 좋겠어요.',\n",
              " '아내분과 대화를 통해 상황이 잘 풀리길 바라요.',\n",
              " '이번에도 대화로 잘 풀렸으면 좋겠어요.',\n",
              " '다른 사람을 만나는 것에 두려움이 없는 모습이 멋지시네요!',\n",
              " '상사와의 대화로 이 문제가 잘 해결하셨으면 좋겠어요.',\n",
              " '민사 소송까지 생각하셨다니 힘내시고 응원하겠습니다.',\n",
              " '아드님을 잘 교육할 수 있는 좋은 방법을 찾기를 바라요.',\n",
              " '매우 속상하시겠네요. 잘 해결됐으면 좋겠어요.',\n",
              " '축하해요. 원하던 직장에 합격했으니 열심히 해봐요!',\n",
              " '모든 것이 잘 풀리길 바라요.',\n",
              " '그런 방법으로 기분전환을 통해 나의 기분이 나아지길 바라요.',\n",
              " '얘기가 잘 되었으면 좋겠어요.',\n",
              " '대화가 잘 풀리셨으면 좋겠네요.',\n",
              " '남편에게 고마운 마음이 잘 전해지면 좋겠어요.',\n",
              " '치료를 받으셔서 꼭 나으시길 바랄게요.',\n",
              " '가족들의 요구가 무척 성가시게 느껴지셨나 봐요.',\n",
              " '불필요한 트집을 잡는 과장때문에 스트레스가 정말 크시겠네요.',\n",
              " '사용자님의 소신대로 앞으로도 편안하시길 바랄게요.',\n",
              " '다른 투자자들과 대화로 해결 방법을 꼭 찾으셨으면 좋겠어요.',\n",
              " '많이 노력했는데 어머니께서 혼내셔서 많이 속상하시군요.',\n",
              " '죽음을 생각하면 혼란스러운 마음이 드시는군요.',\n",
              " '나를 따돌리는 친구들에게 단호하게 표현하려고 하시는군요.',\n",
              " '좋은 경험이라고 생각하고 기분이 더 나아지셨으면 좋겠어요.',\n",
              " '정말 좋은 생각이에요! 동료분들도 많이 감동하실 거 같아요.',\n",
              " '다른 친구에게 조언을 구할 생각이군요.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SleMxxljhzXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1vKrB0CSAqUhIEM9ipVJb",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
