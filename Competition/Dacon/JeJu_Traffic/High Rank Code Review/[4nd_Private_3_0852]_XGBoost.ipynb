{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeP2rU1+rplQJscKWFD9Is",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namwootree/Portfolio/blob/main/Competition/Dacon/JeJu_Traffic/High%20Rank%20Code%20Review/%5B4nd_Private_3_0852%5D_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "w87miDbkDges"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "ensZz3wNDmHI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbEGZyVf_LiX"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from haversine import haversine\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from os.path import join\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "aBz9ZllwDtFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_to_parquet(csv_path, save_name):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.to_parquet(f'./{save_name}.parquet')\n",
        "    del df\n",
        "    gc.collect()\n",
        "    print(save_name, 'Done.')"
      ],
      "metadata": {
        "id": "TE6tnSefDsvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QjnR1EOGDzPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/sample_submission.csv'\n",
        "df_train_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/df_train_V10.csv'\n",
        "df_test_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/df_test_V10.csv'"
      ],
      "metadata": {
        "id": "VRI4HtP1D1YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_to_parquet(df_train_path, 'train')\n",
        "csv_to_parquet(df_test_path, 'test')"
      ],
      "metadata": {
        "id": "GiGG1No_D3lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_parquet('./train.parquet')\n",
        "df_test = pd.read_parquet('./test.parquet')"
      ],
      "metadata": {
        "id": "cZ86RmqdD5f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "v0hWvf29D7je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cyclical_feature(df): # 0\n",
        "    df['sin_time'] = np.sin(2*np.pi*df.base_hour/24)\n",
        "    df['cos_time'] = np.cos(2*np.pi*df.base_hour/24)\n",
        "     \n",
        "def group_time(df): # O\n",
        "    df['group_time'] = '-' \n",
        "    df.loc[(df['base_hour'] < 6), 'group_time'] = '새벽'\n",
        "    df.loc[(df['base_hour'] >=6) & (df['base_hour'] < 12), 'group_time'] = '아침'\n",
        "    df.loc[(df['base_hour'] >= 12) & (df['base_hour'] < 19), 'group_time'] = '오후'\n",
        "    df.loc[(df['base_hour'] >= 19) & (df['base_hour'] <= 24), 'group_time'] = '저녁'\n",
        "    df.loc[(df['group_time']=='-'), 'group_time'] = 'Na'\n",
        "    return df['group_time']\n",
        "\n",
        "def make_month(df): # O\n",
        "    dt = df['base_date'].astype('str')\n",
        "    month_data = pd.to_datetime(dt)\n",
        "    md = month_data.dt.month\n",
        "    return md\n",
        "\n",
        "def group_season(df): # O\n",
        "    df['season'] = '-'\n",
        "    df.loc[(df['month'] == 3) | (df['month'] == 4) | (df['month'] == 5), 'season'] = '봄'\n",
        "    df.loc[(df['month'] == 6) | (df['month'] == 7) | (df['month'] == 8), 'season'] = '여름'\n",
        "    df.loc[(df['month'] == 9) | (df['month'] == 10) | (df['month'] == 11), 'season'] = '가을'\n",
        "    df.loc[(df['month'] == 12) | (df['month'] == 1) | (df['month'] == 2), 'season'] = '겨울'\n",
        "    df.loc[(df['season']=='-'), 'season'] = 'Na'\n",
        "    return df['season']\n",
        "\n",
        "def make_week(df): # 0\n",
        "    dt = df['base_date'].astype('str')\n",
        "    data = pd.to_datetime(dt)\n",
        "    week = [i.weekday() for i in data]\n",
        "    df['week'] = week\n",
        "    df.loc[(df['week'] <= 4), 'week'] = 0\n",
        "    df.loc[(df['week'] > 4), 'week'] = 1\n",
        "    return df['week']\n",
        "\n",
        "\n",
        "def vacation(df): # O\n",
        "    df['vacation'] = '-'\n",
        "    df.loc[(df['month'] == 7) | (df['month'] == 8) | (df['month'] == 1) | (df['month'] == 2), 'vacation'] = 'vacation'\n",
        "    df.loc[(df['month'] == 3) | (df['month'] == 4) | (df['month'] == 5) | (df['month'] == 6) | (df['month'] == 9) | (df['month'] == 10) | (df['month'] == 11) | (df['month'] == 12), 'vacation'] = 'semester'\n",
        "    df.loc[(df['vacation']=='-'), 'vacation'] = 'Na'\n",
        "    return df['vacation']\n",
        "\n",
        "def make_holiday(path): # O\n",
        "    holiday = pd.read_csv(path)\n",
        "    holiday['Year'] = holiday['Year'].astype('str')\n",
        "    holiday['Month'] = holiday['Month'].astype('str')\n",
        "    holiday['Day'] = holiday['Day'].astype('str')\n",
        "\n",
        "    re_month = [holiday['Month'][i].zfill(2) for i in range(len(holiday))]\n",
        "    re_day = [holiday['Day'][i].zfill(2) for i in range(len(holiday))]\n",
        "\n",
        "    holiday['Month'] = re_month\n",
        "    holiday['Day'] = re_day\n",
        "    holiday['base_date'] = holiday['Year'] + holiday['Month'] + holiday['Day']\n",
        "    holiday['holiday'] = 1\n",
        "\n",
        "    holiday = holiday.drop(['Year', 'Month', 'Day', 'Info'], axis=1)\n",
        "\n",
        "    return holiday\n",
        "\n",
        "def make_holiday2(df, holiday): # 0\n",
        "    df['base_date'] = df['base_date'].astype('str')\n",
        "    df = pd.merge(df, holiday, on='base_date', how='left')\n",
        "    df['holiday'] = df['holiday'].fillna(0)\n",
        "\n",
        "    return df['holiday']\n",
        "\n",
        "def make_post_holiday(holiday, df): # 0\n",
        "    holiday_date = holiday['base_date']\n",
        "    holiday_date = pd.to_datetime(holiday_date)\n",
        "    post_holiday = holiday_date - pd.Timedelta(days=1)\n",
        "    holiday['post_date'] = post_holiday\n",
        "    holiday = holiday.drop(['base_date'], axis=1)\n",
        "    holiday = holiday.rename(columns={'holiday': 'post_holiday'})\n",
        "    \n",
        "    df['post_date'] = df['base_date']\n",
        "    df['post_date'] = df['post_date'].astype('str')\n",
        "    df['post_date'] = pd.to_datetime(df['post_date'] )\n",
        "    \n",
        "    df_merge_p = pd.merge(df, holiday, on='post_date', how='left')\n",
        "    df_merge_p['post_holiday'] = df_merge_p['post_holiday'].fillna(0)\n",
        "    \n",
        "    return df_merge_p['post_holiday']\n",
        "\n",
        "def make_pre_holiday(holiday, df): # 0\n",
        "    holiday_date = holiday['base_date']\n",
        "    holiday_date = pd.to_datetime(holiday_date)\n",
        "    pre_holiday = holiday_date + pd.Timedelta(days=1)\n",
        "    holiday['pre_date'] = pre_holiday\n",
        "    holiday = holiday.drop(['base_date'], axis=1)\n",
        "    holiday = holiday.rename(columns={'holiday': 'pre_holiday'})\n",
        "    \n",
        "    df['pre_date'] = df['base_date']\n",
        "    df['pre_date'] = df['pre_date'].astype('str')\n",
        "    df['pre_date'] = pd.to_datetime(df['pre_date'] )\n",
        "    \n",
        "    df_merge = pd.merge(df, holiday, on='pre_date', how='left')\n",
        "    df_merge['pre_holiday'] = df_merge['pre_holiday'].fillna(0)\n",
        "    \n",
        "    return df_merge['pre_holiday']\n",
        "\n",
        "def rest_day(df): # O\n",
        "    df['week'] = df['week'].astype('float')\n",
        "    df['rest'] = df['week'] + df['pre_holiday'] + df['holiday'] + df['post_holiday']\n",
        "    df.loc[(df['rest'] >= 1), 'rest'] = 1\n",
        "    df.loc[(df['rest'] == 0), 'rest'] = 0\n",
        "    \n",
        "def make_dist(df): # 0\n",
        "    start_location = tuple(zip(df['start_latitude'], df['start_longitude']))\n",
        "    end_location = tuple(zip(df['end_latitude'], df['end_longitude']))\n",
        "    hsine = [haversine(s, e) for s, e in zip(start_location, end_location)]\n",
        "\n",
        "    return hsine\n",
        "\n",
        "def make_cluster(train, test): # O\n",
        "    train_c = train[['start_latitude', 'start_longitude']]\n",
        "    test_c = test[['start_latitude', 'start_longitude']]\n",
        "    cluster_centers = np.array([[33.26345514655621116162365069612860679626464843, 126.5203815031463392415389535017311573028564453], [33.37082277149481512878992361947894096374511718, 126.2976713570606790426609222777187824249267578], [33.48077890914120757770433556288480758666992187, 126.4946717292079512162672472186386585235595703] , [33.41815597422977646147046471014618873596191406, 126.7739831436176700663054361939430236816406250]])\n",
        "\n",
        "    k_mean = KMeans(n_clusters=4, init=cluster_centers , random_state = 2)\n",
        "    train['location_cluster'] = k_mean.fit_predict(train_c)\n",
        "    test['location_cluster'] = k_mean.predict(test_c)\n",
        "    \n",
        "    return train, test    \n",
        "\n",
        "# O\n",
        "def jeju_dist(df):\n",
        "    jeju_location = (33.4996213, 126.5311884)\n",
        "    end_location = tuple(zip(df['end_latitude'], df['end_longitude']))\n",
        "    hsine = [haversine(i, jeju_location) for i in end_location]\n",
        "    return hsine\n",
        "\n",
        "def seogwi_dist(df):\n",
        "    jeju_location = (33.2541205, 126.560076)\n",
        "    end_location = tuple(zip(df['end_latitude'], df['end_longitude']))\n",
        "    hsine = [haversine(i, jeju_location) for i in end_location]\n",
        "\n",
        "    return hsine\n",
        "\n",
        "def hanra_dist(df):\n",
        "    jeju_location = (33.361417, 126.529417)\n",
        "    end_location = tuple(zip(df['end_latitude'], df['end_longitude']))\n",
        "    hsine = [haversine(i, jeju_location) for i in end_location]\n",
        "\n",
        "    return hsine\n",
        "\n",
        "def sungsan_dist(df):\n",
        "    jeju_location = (33.458528, 126.94225)\n",
        "    end_location = tuple(zip(df['end_latitude'], df['end_longitude']))\n",
        "    hsine = [haversine(i, jeju_location) for i in end_location]\n",
        "\n",
        "    return hsine\n",
        "\n",
        "def joongmoon_dist(df):\n",
        "    jeju_location = (33.246340915095914, 126.41973291093717)\n",
        "    end_location = tuple(zip(df['end_latitude'], df['end_longitude']))\n",
        "    hsine = [haversine(i, jeju_location) for i in end_location]\n",
        "\n",
        "    return hsine\n",
        "\n",
        "def turn_restricted(df): # O\n",
        "    df['turn_restricted'] = df['start_turn_restricted'] + df['end_turn_restricted']\n",
        "\n",
        "    return df['turn_restricted']\n",
        "\n",
        "def speed(train, test, col, col_name): # O\n",
        "    speed = train.groupby([col, 'maximum_speed_limit'])['target'].agg([(col_name, 'mean')]).reset_index()\n",
        "    train = pd.merge(train, speed, on=[col, 'maximum_speed_limit'], how='left')\n",
        "    test = pd.merge(test, speed, on=[col, 'maximum_speed_limit'], how='left')\n",
        "    test[col_name] = test[col_name].fillna(train[col_name].mode())\n",
        "    return train, test\n",
        "\n",
        "def speed_time(train, test, col, col_name): # O\n",
        "    speed = train.groupby([col, 'base_hour'])['target'].agg([(col_name, 'mean')]).reset_index()\n",
        "    train = pd.merge(train, speed, on=[col, 'base_hour'], how='left')\n",
        "    test = pd.merge(test, speed, on=[col, 'base_hour'], how='left')\n",
        "    test[col_name] = test[col_name].fillna(train[col_name].mode())\n",
        "    return train, test\n",
        "\n",
        "def node_tf(train, test): # O\n",
        "    train['node_TF'] = train['start_node_name'] == train['end_node_name']\n",
        "    test['node_TF'] = test['start_node_name'] == test['end_node_name']\n",
        "    return train, test  \n",
        "    \n",
        "def sm_tm(train, test): # O\n",
        "    st_mean = train.groupby('maximum_speed_limit')['target'].agg([('sm_tm', 'mean')]).reset_index()\n",
        "    st_mean['diff'] = st_mean['maximum_speed_limit'] - st_mean['sm_tm']\n",
        "    st_mean = st_mean.drop(['sm_tm'], axis=1)\n",
        "    train = pd.merge(train, st_mean, on=['maximum_speed_limit'], how='left')\n",
        "    test = pd.merge(test, st_mean, on=['maximum_speed_limit'], how='left')\n",
        "    test['diff'] = test['diff'].fillna(train['diff'].mode())\n",
        "    return train, test\n",
        "\n",
        "def road_name_set(train, test):  \n",
        "    train.loc[train['road_name'][(train['road_type'] == 3)].index, 'road_name'] = '국_지_도'\n",
        "    test.loc[test['road_name'][(test['road_type'] == 3)].index, 'road_name'] = '국_지_도'\n",
        "\n",
        "    train['road_name_set'] = '0'\n",
        "    train.loc[train['road_name'].str.contains('국도'), 'road_name_set'] = 'a'\n",
        "    train.loc[train['road_name'].str.contains('지방도'), 'road_name_set'] = 'a'\n",
        "    train.loc[train['road_name'].str.contains('로'), 'road_name_set'] = 'b'\n",
        "    train.loc[train['road_name'].str.contains('교'), 'road_name_set'] = 'c'\n",
        "    train.loc[train['road_name'].str.contains('국_지_도'), 'road_name_set'] = 'a'\n",
        "\n",
        "    test['road_name_set'] = '0'\n",
        "    test.loc[test['road_name'].str.contains('국도'), 'road_name_set'] = 'a'\n",
        "    test.loc[test['road_name'].str.contains('지방도'), 'road_name_set'] = 'a'\n",
        "    test.loc[test['road_name'].str.contains('로'), 'road_name_set'] = 'b'\n",
        "    test.loc[test['road_name'].str.contains('교'), 'road_name_set'] = 'c'\n",
        "    test.loc[test['road_name'].str.contains('국_지_도'), 'road_name_set'] = 'a'\n",
        "\n",
        "    return train, test\n",
        "\n",
        "def Tourist(df, tour_df): # O\n",
        "    tour_df['end_cartesian'] = tour_df['end_latitude'].astype('str') + ',' + tour_df['end_longitude'].astype('str')\n",
        "    df['end_cartesian'] = df['end_latitude'].astype('str') + ',' + df['end_longitude'].astype('str')\n",
        "    tour_df = tour_df.drop(['end_latitude', 'end_longitude'], axis=1)\n",
        "    df = pd.merge(df, tour_df, how='left', on='end_cartesian')\n",
        "    df['end_cartesian'] = df['end_cartesian'].fillna(tour_df['end_cartesian'].mode())\n",
        "    return df"
      ],
      "metadata": {
        "id": "jo54RO7mD8n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(train_path, test_path, holiday_path, tour_path):\n",
        "    \n",
        "    start = datetime.now()\n",
        "    print('Start time: ', start)\n",
        "    \n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    tour_list = pd.read_csv(tour_path)\n",
        "    \n",
        "    holiday = make_holiday(holiday_path)\n",
        "    post_holiday = make_holiday(holiday_path)\n",
        "    pre_holiday = make_holiday(holiday_path)\n",
        "                    \n",
        "    cyclical_feature(train)\n",
        "    train['group_time'] = group_time(train)\n",
        "    \n",
        "    train['month'] = make_month(train)\n",
        "    train['week'] = make_week(train)\n",
        "    train['post_holiday'] = make_post_holiday(post_holiday, train)\n",
        "    train['pre_holiday'] = make_pre_holiday(pre_holiday, train)\n",
        "    train['holiday'] = make_holiday2(train, holiday)\n",
        "    train['season'] = group_season(train)\n",
        "    train['vacation'] = vacation(train)\n",
        "    \n",
        "    train['distance'] = make_dist(train)\n",
        "    train['jeju_dist'] = jeju_dist(train)\n",
        "    train['seogwi_dist'] = seogwi_dist(train)\n",
        "    train['hanra_dist'] = hanra_dist(train)\n",
        "    train['sungsan_dist'] = sungsan_dist(train)\n",
        "    train['joongmoon_dist'] = joongmoon_dist(train)\n",
        "    \n",
        "    print('Train dataset success !')\n",
        "\n",
        "    cyclical_feature(test)\n",
        "    test['group_time'] = group_time(test)\n",
        "    \n",
        "    test['month'] = make_month(test)\n",
        "    test['week'] = make_week(test)\n",
        "    test['post_holiday'] = make_post_holiday(post_holiday, test)\n",
        "    test['pre_holiday'] = make_pre_holiday(pre_holiday, test)\n",
        "    test['holiday'] = make_holiday2(test, holiday)\n",
        "    test['season'] = group_season(test)\n",
        "    test['vacation'] = vacation(test)\n",
        "    \n",
        "    test['distance'] = make_dist(test)\n",
        "    test['jeju_dist'] = jeju_dist(test)\n",
        "    test['seogwi_dist'] = seogwi_dist(test)\n",
        "    test['hanra_dist'] = hanra_dist(test)\n",
        "    test['sungsan_dist'] = sungsan_dist(test)\n",
        "    test['joongmoon_dist'] = joongmoon_dist(test)\n",
        "    \n",
        "    print('Test dataset success !')\n",
        "\n",
        "    train, test = node_tf(train, test)\n",
        "    train, test = sm_tm(train, test)\n",
        "    train, test = road_name_set(train, test)\n",
        "    \n",
        "    train, test = speed_time(train,test,'road_name','section_speed_time')\n",
        "    train, test = speed_time(train,test,'start_node_name','start_speed_time')\n",
        "    train, test = speed_time(train,test,'end_node_name','end_speed_time')\n",
        "    \n",
        "    train, test = speed(train,test,'road_name','section_speed')\n",
        "    train, test = speed(train,test,'start_node_name','start_speed')\n",
        "    train, test = speed(train,test,'end_node_name','end_speed')\n",
        "    \n",
        "    train = Tourist(train, tour_list)\n",
        "    test = Tourist(test, tour_list)\n",
        "    \n",
        "    train[\"node_TF\"] = train[\"node_TF\"].astype(int)\n",
        "    test[\"node_TF\"] = test[\"node_TF\"].astype(int)\n",
        "    \n",
        "    \n",
        "    str_col = ['day_of_week', 'start_turn_restricted', 'end_turn_restricted',\n",
        "               'road_name', 'start_node_name', 'end_node_name', 'group_time',\n",
        "               'season', 'vacation', 'road_name_set', 'end_cartesian']\n",
        "    \n",
        "    for i in str_col:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(train[i])\n",
        "        train[i] = le.transform(train[i])\n",
        "\n",
        "        for label in np.unique(test[i]):\n",
        "            if label not in le.classes_:\n",
        "                le.classes_ = np.append(le.classes_, label)\n",
        "        test[i] = le.transform(test[i])\n",
        "\n",
        "    train['turn_restricted'] = turn_restricted(train)\n",
        "    test['turn_restricted'] = turn_restricted(test)\n",
        "\n",
        "    rest_day(train)\n",
        "    rest_day(test)\n",
        "    \n",
        "    train, test = make_cluster(train, test)\n",
        "    \n",
        "    X = train.drop(    \n",
        "        ['id', 'base_date', 'target', 'vehicle_restricted', 'height_restricted',\n",
        "        'post_date', 'pre_date'], axis=1\n",
        "    )\n",
        "\n",
        "    y = train['target']\n",
        "\n",
        "    test = test.drop(\n",
        "        ['id', 'base_date', 'vehicle_restricted', 'height_restricted',\n",
        "         'post_date', 'pre_date'], axis=1\n",
        "    )\n",
        "\n",
        "    End = datetime.now()\n",
        "    print(f'End time: {End}')\n",
        "    print('Play time: ', End - start)\n",
        "    \n",
        "    return X, y, test\n"
      ],
      "metadata": {
        "id": "nWPWSD37ES6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = './train.csv'\n",
        "test_x = './test.csv'\n",
        "holiday = './국가공휴일.csv'\n",
        "tour_path = './관광지2000.csv'\n",
        "X, y, test = make_dataset(train, test_x, holiday,tour_path)"
      ],
      "metadata": {
        "id": "8uAHyOoGEXRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "PX7KNWUhEYLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "\n",
        "params = {'n_estimators': 4693, 'max_depth': 15, 'min_child_weight': 4, 'gamma': 1, 'learning_rate': 0.018,\n",
        "          'colsample_bytree': 0.9015018647603987, 'lambda': 1.386941960727803, 'alpha': 0.10534800837686535, 'subsample': 1.0}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=9, shuffle=True, random_state=404)\n",
        "\n",
        "folds = []\n",
        "\n",
        "for train_idx, val_idx in skf.split(X, y):\n",
        "    folds.append((train_idx, val_idx))\n",
        "\n",
        "XGB_model = {}\n",
        "\n",
        "for f in range(9):\n",
        "    print(\n",
        "        f'===================================={f+1}============================================')\n",
        "    train_idx, val_idx = folds[f]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = X.iloc[train_idx], X.iloc[val_idx], y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    XGB = XGBRegressor(**params, tree_method='gpu_hist',\n",
        "                       gpu_id=0, random_state=404)\n",
        "    XGB.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = XGB.predict(x_val)\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    print(f\"{f + 1} Fold MAE = {mae}\")\n",
        "    XGB_model[f] = XGB\n",
        "    print(f'================================================================================\\n\\n')\n",
        "\n",
        "\n",
        "for fold in range(9):\n",
        "    sample_submission['target'] += XGB_model[fold].predict(test)/9"
      ],
      "metadata": {
        "id": "J3PmAt-JEY8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "8CW6ZwuyEjNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(df_submission_path)"
      ],
      "metadata": {
        "id": "OXIqp4u_EmIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission['target'] = round(sample_submission['target'])\n",
        "sample_submission.to_csv(\"./submit.csv\", index=False)"
      ],
      "metadata": {
        "id": "IYjObhOjEdqW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}