{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA9S0fWqY7FDi3ASwDGveq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namwootree/Portfolio/blob/main/Competition/Dacon/JeJu_Traffic/High%20Rank%20Code%20Review/%5B3nd_Private_3_08467%5D_LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "LS_aEHo0liFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "LzHiBmGNljaf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCzvvZLElQAL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "\n",
        "from glob import glob\n",
        "from scipy import interpolate\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "from pytz import timezone\n",
        "\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns \n",
        "\n",
        "import datetime\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns',None)"
      ],
      "metadata": {
        "id": "fuIoCC5sloTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "bBXd8zhDlowr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_to_parquet(csv_path, save_name):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.to_parquet(f'./{save_name}.parquet')\n",
        "    del df\n",
        "    gc.collect()\n",
        "    print(save_name, 'Done.')"
      ],
      "metadata": {
        "id": "W1X2W8w1lplV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2IT61Vfwlusy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/sample_submission.csv'\n",
        "df_train_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/train.csv'\n",
        "df_test_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/test.csv'"
      ],
      "metadata": {
        "id": "dCj5QAXQlvLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_to_parquet(df_train_path, 'train')\n",
        "csv_to_parquet(df_test_path, 'test')"
      ],
      "metadata": {
        "id": "-Btrk-2slzMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet('/content/train.parquet')\n",
        "test = pd.read_parquet('/content/test.parquet')"
      ],
      "metadata": {
        "id": "2Qjfo1Axl1nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ACTtOpDkl4Xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data type -> int"
      ],
      "metadata": {
        "id": "_yjPB5AQmRXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation 할 때는 True, 제출 시에는 False\n",
        "EVAL = False"
      ],
      "metadata": {
        "id": "0GuAN1w2l5lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if EVAL:\n",
        "    train['base_date'] = train['base_date'].astype('str') \n",
        "    train['year'] = train['base_date'].apply(lambda x: x[:4]).astype('int')    \n",
        "    train['month'] = train['base_date'].apply(lambda x: x[4:6]).astype('int')\n",
        "    train['day'] = train['base_date'].apply(lambda x: x[6:8]).astype('int')   \n",
        "    \n",
        "    test = train.query('month==7 and year==2022 and day>15').reset_index(drop=True)\n",
        "    train = train.query('month!=7 or year!=2022 or day<=15').reset_index(drop=True)\n",
        "    train.shape, test.shape\n",
        "    \n",
        "else:\n",
        "    train['base_date'] = train['base_date'].astype('str')     \n",
        "    train['year'] = train['base_date'].apply(lambda x: x[:4]).astype('int')    \n",
        "    train['month'] = train['base_date'].apply(lambda x: x[4:6]).astype('int')    \n",
        "    train['day'] = train['base_date'].apply(lambda x: x[6:8]).astype('int')\n",
        "    \n",
        "    test['base_date'] = test['base_date'].astype('str') \n",
        "    test['year'] = test['base_date'].apply(lambda x: x[:4]).astype('int')    \n",
        "    test['month'] = test['base_date'].apply(lambda x: x[4:6]).astype('int')    \n",
        "    test['day'] = test['base_date'].apply(lambda x: x[6:8]).astype('int')\n",
        "    train.shape, test.shape"
      ],
      "metadata": {
        "id": "p7PI7tVemGtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding"
      ],
      "metadata": {
        "id": "VPwWapGkmVU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str_col = ['day_of_week','start_turn_restricted','end_turn_restricted',\n",
        "           'road_name','road_type','road_rating','start_node_name','end_node_name',\n",
        "           'start_latitude','end_latitude','start_longitude','end_longitude']"
      ],
      "metadata": {
        "id": "suxRuMBIma3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in str_col:\n",
        "    le = LabelEncoder()\n",
        "    le=le.fit(train[i])\n",
        "    train[i]=le.transform(train[i])\n",
        "    \n",
        "    for label in np.unique(test[i]):\n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test[i]=le.transform(test[i])"
      ],
      "metadata": {
        "id": "VGPfzzKzmW4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파생변수 생성"
      ],
      "metadata": {
        "id": "aP3wV37Tmcw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주요 항목별 target의 train 데이터셋 평균과 표준편차를 파생변수로 생성\n",
        "\n",
        "* [시간, 제한속도]별 target 평균은 별도 파생변수로 생성\n",
        "* [시간]별 targe평균에 대한 [시간,제한속도]별 target평균의 비율 추가\n",
        "* 파생변수는 train데이터셋만으로 생성한 이후, test 데이터셋으로 merge"
      ],
      "metadata": {
        "id": "LDaEhewemf6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 주요 컬럼에 대해서 컬럼별 target통계(평균) 추가\n",
        " train 데이터셋만으로 통계를 내고, test에는 merge만 함"
      ],
      "metadata": {
        "id": "l_QMX_8jmwuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['day_of_week', 'base_hour','road_name','start_node_name',\n",
        "         'end_node_name','maximum_speed_limit','start_latitude',\n",
        "         'end_latitude','start_longitude','end_longitude']"
      ],
      "metadata": {
        "id": "rdmFwJT7m4CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in names:\n",
        "    print(name)\n",
        "    df1 = train.groupby(name).mean().reset_index()[[name,'target']].rename(columns={'target':f'{name}_mean_target'})\n",
        "    train = pd.merge(train,df1,on=name,how='left')\n",
        "    \n",
        "    test = pd.merge(test,df1,on=name,how='left')       \n",
        "\n",
        "df1 = train.groupby(['base_hour','maximum_speed_limit']).mean().reset_index()[[ 'base_hour','maximum_speed_limit','target']].rename(columns={'target':'whs_mean_target'})\n",
        "train = pd.merge(train,df1,on=[ 'base_hour','maximum_speed_limit'],how='left')\n",
        "\n",
        "test = pd.merge(test,df1,on=[ 'base_hour','maximum_speed_limit'],how='left')  "
      ],
      "metadata": {
        "id": "D1vnlpO0mqER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ['base_hour'] 통계와 ['base_hour','maximun_speed_limit']통계간의 차이 비율 추가"
      ],
      "metadata": {
        "id": "FCCVapWwm0qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = train.groupby(['base_hour']).mean().reset_index()[[ 'base_hour','target']].rename(columns={'target':'whs_mean_target2'})\n",
        "train = pd.merge(train,df1,on=[ 'base_hour'],how='left')\n",
        "train['whs_delta_targe'] = (train['whs_mean_target']-train['whs_mean_target2'])/train['whs_mean_target2']\n",
        "train = train.drop('whs_mean_target2',axis=1)\n",
        "\n",
        "test = pd.merge(test,df1,on=['base_hour'],how='left')    \n",
        "test['whs_delta_targe'] = (test['whs_mean_target']-test['whs_mean_target2'])/test['whs_mean_target2']\n",
        "test = test.drop('whs_mean_target2',axis=1)"
      ],
      "metadata": {
        "id": "_Q3oG0WDmela"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 주요 컬럼에 대해서 컬럼별 target통계(표준편차)추가\n",
        "\n",
        " train 데이터셋만으로 통계를 내고, test에는 merge만 함"
      ],
      "metadata": {
        "id": "l_vu7H0sm8um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['day_of_week', 'base_hour','road_name','start_node_name',\n",
        "         'end_node_name','maximum_speed_limit','start_latitude',\n",
        "         'end_latitude','start_longitude','end_longitude']"
      ],
      "metadata": {
        "id": "RGgg-x33m-qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in names:\n",
        "    print(name)\n",
        "    df1 = train.groupby(name).std().reset_index()[[name,'target']].rename(columns={'target':f'{name}_std_target'})\n",
        "    train = pd.merge(train,df1,on=name,how='left')\n",
        "    \n",
        "    test = pd.merge(test,df1,on=name,how='left')       \n",
        "\n",
        "df1 = train.groupby([ 'base_hour','maximum_speed_limit']).std().reset_index()[['base_hour','maximum_speed_limit','target']].rename(columns={'target':'whs_std_target'})\n",
        "train = pd.merge(train,df1,on=[ 'base_hour','maximum_speed_limit'],how='left')\n",
        "\n",
        "test = pd.merge(test,df1,on=[ 'base_hour','maximum_speed_limit'],how='left')      "
      ],
      "metadata": {
        "id": "uG9_jDLHnEvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시간 cos/sin 변환 추가"
      ],
      "metadata": {
        "id": "sAHABFLWnVxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['cos_time'] = np.cos(2*np.pi*(train['base_hour']/24))\n",
        "train['sin_time'] = np.sin(2*np.pi*(train['base_hour']/24))\n",
        "\n",
        "test['cos_time'] = np.cos(2*np.pi*(test['base_hour']/24))\n",
        "test['sin_time'] = np.sin(2*np.pi*(test['base_hour']/24))"
      ],
      "metadata": {
        "id": "eIH7nU8CnWz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill NaN"
      ],
      "metadata": {
        "id": "h6Z2BLFvnH3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.fillna(0)\n",
        "test = test.fillna(0)"
      ],
      "metadata": {
        "id": "x_tG9ZUSnKKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data type -> category"
      ],
      "metadata": {
        "id": "nQIqYIE8nMYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[str_col] = train[str_col].astype('category')\n",
        "test[str_col] = test[str_col].astype('category')"
      ],
      "metadata": {
        "id": "3NujT_H-nOJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "9Svs5vV7napZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LGBM"
      ],
      "metadata": {
        "id": "OrpsId3DnpqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lgbm_model_train(x_train, y_train, x_valid, y_valid, lr,seed) :\n",
        "    params = {'learning_rate': lr, \n",
        "              'max_depth': 16, \n",
        "              'boosting': 'gbdt', \n",
        "              'objective': 'regression',  \n",
        "              'is_training_metric': True, \n",
        "              'num_leaves': 5000, \n",
        "              'feature_fraction': 0.9, \n",
        "              'bagging_fraction': 0.8, \n",
        "              'seed':seed,\n",
        "              'num_threads':8,\n",
        "              'metric':{'l2','l1'},\n",
        "              'num_iterations':2000,\n",
        "             }\n",
        "\n",
        "    model = lgb.train(params, \n",
        "                   train_set = lgb.Dataset(data = x_train, label = y_train),\n",
        "                   num_boost_round = 2000, \n",
        "                   valid_sets = lgb.Dataset(data = x_valid, label = y_valid), \n",
        "                   init_model = None, \n",
        "                   early_stopping_rounds = 200,\n",
        "                   verbose_eval = 50\n",
        "                    )    \n",
        "    return model"
      ],
      "metadata": {
        "id": "sSgxkWDLnbVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경고 끄기\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "9Y6y3ztZniLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ],
      "metadata": {
        "id": "dXm6YvzPnq1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(train, test, rs, ts):\n",
        "  \n",
        "    seed_l = [1000,1001,51,51,191,1001,67,51,51,191]\n",
        "    lr_l = [0.025, 0.03, 0.11,0.05, 0.07, 0.08, 0.02, 0.06, 0.12, 0.1]\n",
        "    model = []\n",
        "    \n",
        "    train = train.drop(['id','base_date','year','day','multi_linked','vehicle_restricted','height_restricted', 'connect_code'], axis=1)\n",
        "\n",
        "    st = datetime.datetime.now()\n",
        "    print('start time : ',st)\n",
        "\n",
        "    # train 데이터셋을 99%로 랜덤 분할하여, 20번 수행\n",
        "    if EVAL:\n",
        "        split = StratifiedShuffleSplit(n_splits=10, test_size=ts, random_state=rs)\n",
        "    else:\n",
        "        split = StratifiedShuffleSplit(n_splits=10, test_size=ts, random_state=rs)   \n",
        "\n",
        "    i=0\n",
        "    for train_idx, valid_idx in split.split(train ,train[['month']]): \n",
        "        X_train = train.loc[train_idx].drop(['target'], axis=1)\n",
        "        y_train = train.loc[train_idx]['target']\n",
        "\n",
        "        X_valid = train.loc[valid_idx].drop(['target'], axis=1)\n",
        "        y_valid = train.loc[valid_idx]['target']\n",
        "\n",
        "        seed = seed_l[i%10]\n",
        "        lr = lr_l[i%10]\n",
        "    #학습 \n",
        "        print('random state : ',rs, 'test size : ',ts, 'seed : ',seed, 'lr : ',lr, 'seq : ',i)\n",
        "        model_ = lgbm_model_train(X_train,y_train,X_valid,y_valid, lr,seed)   \n",
        "        model.append(model_)\n",
        "        \n",
        "        ed = datetime.datetime.now()\n",
        "        print(i, 'Elapsed time : ', ed -st )\n",
        "        st = ed\n",
        "        i += 1   \n",
        "  \n",
        "    return model"
      ],
      "metadata": {
        "id": "5WJWHvWQnr-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공휴일 관련 변수 별 모델 학습"
      ],
      "metadata": {
        "id": "CsN_n3TlplV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "공휴일과 인접한 주말도 포함한 버전, 공휴일만 포함한 버전, 극성수기 포함 등 3개를 사용\n",
        "* 관광지 특성상 공휴일과 인접 주말에 교통이 혼잡할 것으로 예상\n",
        "* 공휴일은 출퇴근 시간대가 없으므로 일반적인 주중 패턴과 다를 것으로 예상\n",
        "공유일 변수를 추가했을 때 예측정확도가 올라가는 것을 확인함"
      ],
      "metadata": {
        "id": "uHd2cNnqpuFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 공휴일 인접 주말 포함"
      ],
      "metadata": {
        "id": "N9QORYtnpzaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_l = [0.01,  0.05]\n",
        "rs_l = [51, 1000]\n",
        "\n",
        "# 공휴일 인접 주말 포함\n",
        "hday = ['20210918','20210919','20210920','20210921','20210922','20211002','20211003','20211004','20211009',\n",
        "        '20211010','20211011','20211225','20211226','20220101','20220102','20220129','20220130','20220131',\n",
        "        '20220201','20220202','20220301','20220309','20220505','20220506','20220507','20220508','20220601',\n",
        "        '20220604','20220605','20220606','20220813','20220814','20220815'\n",
        "]\n",
        "\n",
        "ncol_l = []\n",
        "model_1 = []\n",
        "\n",
        "for i in range(2):\n",
        "    train['hday'] = train['base_date'].apply(lambda x: 1 if x in hday else 0)\n",
        "    test['hday'] = test['base_date'].apply(lambda x: 1 if x in hday else 0)   \n",
        "    \n",
        "    model_ = run(train, test, rs_l[i] , ts_l[i])\n",
        "    model_1.extend(model_)"
      ],
      "metadata": {
        "id": "HwWVA9CzpsDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 공휴일만"
      ],
      "metadata": {
        "id": "vyxlY_rQp4Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_l = [0.01,  0.05]\n",
        "rs_l = [51, 1000]\n",
        "\n",
        "#공휴일만\n",
        "hday = ['20210920','20210921','20210922', '20211004','20211011','20220131','20220201','20220202','20220301',\n",
        "        '20220309','20220505','20220601','20220606','20220815']\n",
        "\n",
        "ncol_l = []\n",
        "model_2 = []\n",
        "\n",
        "for i in range(2):\n",
        "    train['hday'] = train['base_date'].apply(lambda x: 1 if x in hday else 0)\n",
        "    \n",
        "    model_ = run(train, test, rs_l[i] , ts_l[i])\n",
        "    model_2.extend(model_)"
      ],
      "metadata": {
        "id": "41QzQ4qrp7xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제주 극성수기 포함"
      ],
      "metadata": {
        "id": "GQBfBOVKp-US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_l = [0.01,  0.05]\n",
        "rs_l = [51, 1000]\n",
        "\n",
        "#제주 극성수기 포함\n",
        "hday = ['20210918','20210919','20210920','20210921','20210922','20211002','20211003','20211004','20211009',\n",
        "        '20211010','20211011','20211225','20211226','20220101','20220102','20220129','20220130','20220131',\n",
        "        '20220201','20220202','20220301','20220309','20220505','20220506','20220507','20220508','20220601',\n",
        "        '20220604','20220605','20220606','20220729','20220730','20220731','20220801','20220802','20220803',\n",
        "        '20220804','20220805','20220813','20220814','20220815'\n",
        "]\n",
        "\n",
        "ncol_l = []\n",
        "model_3 = []\n",
        "\n",
        "for i in range(2):\n",
        "    train['hday'] = train['base_date'].apply(lambda x: 1 if x in hday else 0)\n",
        "    \n",
        "    model_ = run(train, test, rs_l[i] , ts_l[i])\n",
        "    model_3.extend(model_)"
      ],
      "metadata": {
        "id": "vy3teetCp_xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 추론"
      ],
      "metadata": {
        "id": "Ca_kZ046qHs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 공휴일 인접 주말 포함"
      ],
      "metadata": {
        "id": "A02H01bqqKX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hday = ['20210918','20210919','20210920','20210921','20210922','20211002','20211003','20211004','20211009',\n",
        "        '20211010','20211011','20211225','20211226','20220101','20220102','20220129','20220130','20220131',\n",
        "        '20220201','20220202','20220301','20220309','20220505','20220506','20220507','20220508','20220601',\n",
        "        '20220604','20220605','20220606','20220813','20220814','20220815'\n",
        "]\n",
        "\n",
        "test_ = test.copy()\n",
        "test_['hday'] = test_['base_date'].apply(lambda x: 1 if x in hday else 0)   \n",
        "test_ = test_.drop(['id','base_date','year','day','multi_linked','vehicle_restricted', 'height_restricted','connect_code'], axis=1)  \n",
        "\n",
        "df_pred = pd.DataFrame()\n",
        "i = 0\n",
        "\n",
        "for i in range(20):    \n",
        "    model_ = model_1[i]\n",
        "    pred = model_.predict(test_)        \n",
        "    df_pred[f'pred_{i}'] = pred \n",
        "\n",
        "    i += 1   "
      ],
      "metadata": {
        "id": "UPxG7ZJcqIq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 공휴일만"
      ],
      "metadata": {
        "id": "JvVXxbcYqMpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hday = ['20210920','20210921','20210922', '20211004','20211011','20220131','20220201','20220202','20220301',\n",
        "        '20220309','20220505','20220601','20220606','20220815']\n",
        "\n",
        "test_ = test.copy()\n",
        "test_['hday'] = test_['base_date'].apply(lambda x: 1 if x in hday else 0)   \n",
        "test_ = test_.drop(['id','base_date','year','day','multi_linked','vehicle_restricted', 'height_restricted','connect_code'], axis=1)  \n",
        "\n",
        "i = 0\n",
        "for i in range(20):    \n",
        "    model_ = model_2[i]\n",
        "    pred = model_.predict(test_)        \n",
        "    df_pred[f'pred_{i+20}'] = pred \n",
        "\n",
        "    i += 1   "
      ],
      "metadata": {
        "id": "bhJYQZX6qNbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제주 극성수기 포함"
      ],
      "metadata": {
        "id": "O7X4IVUPqO0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hday = ['20210918','20210919','20210920','20210921','20210922','20211002','20211003','20211004','20211009',\n",
        "        '20211010','20211011','20211225','20211226','20220101','20220102','20220129','20220130','20220131',\n",
        "        '20220201','20220202','20220301','20220309','20220505','20220506','20220507','20220508','20220601',\n",
        "        '20220604','20220605','20220606','20220729','20220730','20220731','20220801','20220802','20220803',\n",
        "        '20220804','20220805','20220813','20220814','20220815'\n",
        "]\n",
        "\n",
        "test_ = test.copy()\n",
        "test_['hday'] = test_['base_date'].apply(lambda x: 1 if x in hday else 0)   \n",
        "test_ = test_.drop(['id','base_date','year','day','multi_linked','vehicle_restricted', 'height_restricted','connect_code'], axis=1)  \n",
        "\n",
        "i = 0\n",
        "for i in range(20):    \n",
        "    model_ = model_3[i]\n",
        "    pred = model_.predict(test_)        \n",
        "    df_pred[f'pred_{i+40}'] = pred \n",
        "\n",
        "    i += 1   "
      ],
      "metadata": {
        "id": "giCkFhiWqQaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 종합 (앙상블)"
      ],
      "metadata": {
        "id": "UTvgXuNqqSCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred['pred'] = df_pred.mean(axis=1)  \n",
        "df_pred"
      ],
      "metadata": {
        "id": "Sn1He1qJqTrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 중요도 확인"
      ],
      "metadata": {
        "id": "jZfrR7llqZA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split 중요도"
      ],
      "metadata": {
        "id": "iiMQXF7yqc13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = train.drop('target',axis=1).columns\n",
        "fig, ax = plt.subplots(figsize=(10, 15))\n",
        "ax = lgb.plot_importance(model_, max_num_features=len(FEATURES), importance_type='split',ax=ax)\n",
        "\n",
        "ax.set(title=f'Feature Importance (split)',\n",
        "    xlabel='Feature Importance',\n",
        "    ylabel='Features')"
      ],
      "metadata": {
        "id": "4zwhCpQ7qkBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gain 중요도"
      ],
      "metadata": {
        "id": "H3oJfazOqglT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = train.drop('target',axis=1).columns\n",
        "fig, ax = plt.subplots(figsize=(10, 15))\n",
        "ax = lgb.plot_importance(model_, max_num_features=len(FEATURES), importance_type='gain',ax=ax)\n",
        "ax.set(title=f'Feature Importance (gain)',\n",
        "    xlabel='Feature Importance',\n",
        "    ylabel='Features')"
      ],
      "metadata": {
        "id": "W5DwgVcXqceJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "55pD0-cDqmm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "gDSzDG8jqom0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission['target'] = df_pred.pred.values\n",
        "sample_submission.to_csv(\"./submit.csv\", index = False)"
      ],
      "metadata": {
        "id": "xBfSgwMiqqIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission\n"
      ],
      "metadata": {
        "id": "CNuezZ6kqr8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}