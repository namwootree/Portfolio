{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGIB+/o8LV7pDFR1X2aVOt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namwootree/Portfolio/blob/main/Competition/Dacon/JeJu_Traffic/High%20Rank%20Code%20Review/%5B2nd_Private_3_08350%5D_Optuna_Catboost_XGBoost_LGBM_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "gm5SV1DBXruS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU"
      ],
      "metadata": {
        "id": "tlkVCk4zcl0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "WXLN5si_cuST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "yTFgng1uXtFd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmr1gMtVXah0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import gc\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from haversine import haversine\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "NaW0YfljXxMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_to_parquet(csv_path, save_name):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.to_parquet(f'./{save_name}.parquet')\n",
        "    del df\n",
        "    gc.collect()\n",
        "    print(save_name, 'Done.')"
      ],
      "metadata": {
        "id": "tdb3uuFeXwkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lUjxoF6gaDeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/sample_submission.csv'\n",
        "df_train_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/train.csv'\n",
        "df_test_path = '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/제주도 도로 교통량 예측/data/test.csv'"
      ],
      "metadata": {
        "id": "kJNskp5RaD1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_to_parquet(df_train_path, 'train')\n",
        "csv_to_parquet(df_test_path, 'test')"
      ],
      "metadata": {
        "id": "SIxZc7fuaIax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet('/content/train.parquet')\n",
        "test = pd.read_parquet('/content/test.parquet')"
      ],
      "metadata": {
        "id": "84WNAsdEaIsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "klNb9uIJaLkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop"
      ],
      "metadata": {
        "id": "0qSrHkQnaRuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['vehicle_restricted', 'id', 'height_restricted'], axis = 1, inplace = True)\n",
        "test.drop(['vehicle_restricted', 'id', 'height_restricted'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "jIWdt359aQRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## start_node_name과 end_node_name을 key값으로 만들어 LabelEncoding"
      ],
      "metadata": {
        "id": "MlF4BAO1dpy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "W9LED9B8dt5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['node_combination'] = train['start_node_name'] + '_' + train['end_node_name']\n",
        "test['node_combination'] = test['start_node_name'] + '_' + test['end_node_name']"
      ],
      "metadata": {
        "id": "e-GKhUxHdvhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['node_combination'] = le.fit_transform(train['node_combination'])"
      ],
      "metadata": {
        "id": "09lUlEMgdwyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in np.unique(test['node_combination']) :\n",
        "    if category not in le.classes_ :\n",
        "        le.classes_ = np.append(le.classes_, label)\n",
        "test['node_combination'] = le.transform(test['node_combination'])"
      ],
      "metadata": {
        "id": "Xpi-dHaCdyBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 위경도 좌표만으로 Clustering(KMeans)"
      ],
      "metadata": {
        "id": "qSZ_Ifx8d0aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering Plotting 결과 군집 수가 6일 때 각 좌표가 명확히 구분되어 6으로 설정"
      ],
      "metadata": {
        "id": "q6_MkOpgd32r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "km = KMeans(n_clusters = 6, max_iter = 1000, random_state = 42, n_init = 15)"
      ],
      "metadata": {
        "id": "VtiRaBjCd7zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['gps_cls'] = km.fit_predict(train[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']])\n",
        "test['gps_cls'] = km.predict(test[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']])"
      ],
      "metadata": {
        "id": "aEvqAlFWd8Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공휴일 전후 1 ~ 2일 여부"
      ],
      "metadata": {
        "id": "dbQNJ4nleJan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적인 공휴일 기준으로 전후 1 ~ 2일을 기간을 더 두어 binary화"
      ],
      "metadata": {
        "id": "qNZXiUy1eOI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['base_date'] = train['base_date'].astype(str)\n",
        "test['base_date'] = test['base_date'].astype(str)"
      ],
      "metadata": {
        "id": "OA23zNCPeN7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['date'] = train['base_date'].str[4:]\n",
        "test['date'] = test['base_date'].str[4:]"
      ],
      "metadata": {
        "id": "OGrqET9feRJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_days = ['1231', '0101', '0102', '0129', '0130', '0131', '0201', '0202', '0228', '0229', '0230', '0301', '0302', \n",
        "          '0505', '0506', '0507', '0508', '0605', '0607', '0606', '0814', '0815', '0816', '0920', '0921', '0504',\n",
        "          '0922', '1002', '1003', '1004', '1008', '1009', '1010', '1224', '1225', '1226']"
      ],
      "metadata": {
        "id": "N35rIdRneSfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['in_h_days'] = train['date'].isin(h_days)\n",
        "test['in_h_days'] = test['date'].isin(h_days)"
      ],
      "metadata": {
        "id": "Fmz7tv-XeT5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 년도"
      ],
      "metadata": {
        "id": "17gTS4YueYPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['base_date'] = pd.to_datetime(train['base_date'])\n",
        "test['base_date'] = pd.to_datetime(test['base_date'])"
      ],
      "metadata": {
        "id": "5fpL5amkeaJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['year'] = train['base_date'].dt.year\n",
        "test['year'] = test['base_date'].dt.year"
      ],
      "metadata": {
        "id": "uCnon6TeedtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 월"
      ],
      "metadata": {
        "id": "riwtOiDBebgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['month'] = train['base_date'].dt.month\n",
        "test['month'] = test['base_date'].dt.month"
      ],
      "metadata": {
        "id": "9v1jM29xebTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최고 제한 속도로 도로 주행시 소요 시간"
      ],
      "metadata": {
        "id": "abPYOy70egqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dist = []\n",
        "for i, v in enumerate(train[['start_latitude', 'end_latitude', 'start_longitude', 'end_longitude']].values) :\n",
        "    dist.append(haversine((v[0], v[2]), (v[1], v[3]), unit = 'km'))"
      ],
      "metadata": {
        "id": "Mrjg-SNaeiYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['at_time'] = 60 * pd.Series(dist) / train['maximum_speed_limit']"
      ],
      "metadata": {
        "id": "_ZLguiLwelx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = []\n",
        "for i, v in enumerate(test[['start_latitude', 'end_latitude', 'start_longitude', 'end_longitude']].values) :\n",
        "    dist.append(haversine((v[0], v[2]), (v[1], v[3]), unit = 'km'))"
      ],
      "metadata": {
        "id": "oCPAMOQ3emOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['at_time'] = 60 * pd.Series(dist) / test['maximum_speed_limit']"
      ],
      "metadata": {
        "id": "wb-1FMlueoaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "qIdx3STOeo7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 방위각"
      ],
      "metadata": {
        "id": "pkfJ4bXuexTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Azimuth(lat1, lng1, lat2, lng2):\n",
        "    Lat1 = math.radians(lat1)\n",
        "    Lat2 = math.radians(lat2)\n",
        "    Lng1 = math.radians(lng1)\n",
        "    Lng2 = math.radians(lng2)\n",
        "    \n",
        "    y = math.sin(Lng2 - Lng1) * math.cos(Lat2)\n",
        "    x = math.cos(Lat1) * math.sin(Lat2) - math.sin(Lat1) * math.cos(Lat2) * math.cos(Lng2-Lng1)\n",
        "    z = math.atan2(y, x)\n",
        "\n",
        "    a = np.rad2deg(z)\n",
        "    \n",
        "    if(a < 0):\n",
        "        a = 180 + (180 + a)\n",
        "    return a"
      ],
      "metadata": {
        "id": "UUzuSgSNeyQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['degree'] = [Azimuth(v[0], v[1], v[2], v[3]) for i, v in enumerate(train[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']].values)]\n",
        "test['degree'] = [Azimuth(v[0], v[1], v[2], v[3]) for i, v in enumerate(test[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']].values)]"
      ],
      "metadata": {
        "id": "6pUIK4xHe16T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_season(x) :\n",
        "    \n",
        "    if x in [9, 10, 11] :\n",
        "        return 3\n",
        "    elif x in [12, 1, 2] :\n",
        "        return 2\n",
        "    elif x in [3, 4, 5, 6] :\n",
        "        return 1\n",
        "    else :\n",
        "        return 0"
      ],
      "metadata": {
        "id": "Pxxt1-cwe48b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['season'] = train['month'].apply(get_season)\n",
        "test['season'] = test['month'].apply(get_season)"
      ],
      "metadata": {
        "id": "zUU7_qX-e6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 계절"
      ],
      "metadata": {
        "id": "MH50xoX2fLdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_season(x) :\n",
        "    \n",
        "    if x in [9, 10, 11] :\n",
        "        return 3\n",
        "    elif x in [12, 1, 2] :\n",
        "        return 2\n",
        "    elif x in [3, 4, 5, 6] :\n",
        "        return 1\n",
        "    else :\n",
        "        return 0"
      ],
      "metadata": {
        "id": "3ALASk59fMVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['season'] = train['month'].apply(get_season)\n",
        "test['season'] = test['month'].apply(get_season)"
      ],
      "metadata": {
        "id": "Gw2jjv1ffNdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 요일"
      ],
      "metadata": {
        "id": "H7agiik1e8AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적인 요일 순서대로가 아닌 LabelEncoding으로 진행"
      ],
      "metadata": {
        "id": "PHzVYEXte_QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['day_of_week'] = le.fit_transform(train['day_of_week'])"
      ],
      "metadata": {
        "id": "c8BtAGWje9If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in np.unique(test['day_of_week']) :\n",
        "    if category not in le.classes_ :\n",
        "        le.classes_ = np.append(le.classes_, label)\n",
        "test['day_of_week'] = le.transform(test['day_of_week'])"
      ],
      "metadata": {
        "id": "QsOMOhAUfA9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 도로명"
      ],
      "metadata": {
        "id": "Gp3olXpXfFkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "도로명 LabelEncoding"
      ],
      "metadata": {
        "id": "owew82oqfRW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['road_name'] = le.fit_transform(train['road_name'])"
      ],
      "metadata": {
        "id": "NksIdN0nfPnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in np.unique(test['road_name']) :\n",
        "    if category not in le.classes_ :\n",
        "        le.classes_ = np.append(le.classes_, label)\n",
        "test['road_name'] = le.transform(test['road_name'])"
      ],
      "metadata": {
        "id": "UKkARWlBfTYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시작 노드 == 종료 노드 여부"
      ],
      "metadata": {
        "id": "LdZJAkHpfWJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['node_same'] = train['start_node_name'] == train['end_node_name']\n",
        "test['node_same'] = test['start_node_name'] == test['end_node_name']"
      ],
      "metadata": {
        "id": "9jS7BztPfVGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기타 칼럼 LabelEncoding"
      ],
      "metadata": {
        "id": "HDZJIL5afahd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['start_turn_restricted'] = le.fit_transform(train['start_turn_restricted'])"
      ],
      "metadata": {
        "id": "7gLgwyGRfdWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in np.unique(test['start_turn_restricted']) :\n",
        "    if category not in le.classes_ :\n",
        "        le.classes_ = np.append(le.classes_, label)\n",
        "        \n",
        "test['start_turn_restricted'] = le.transform(test['start_turn_restricted'])"
      ],
      "metadata": {
        "id": "Gd8t3Wunffe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['end_turn_restricted'] = le.fit_transform(train['end_turn_restricted'])"
      ],
      "metadata": {
        "id": "qv35zP4jfhJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in np.unique(test['end_turn_restricted']) :\n",
        "    if category not in le.classes_ :\n",
        "        le.classes_ = np.append(le.classes_, label)\n",
        "test['end_turn_restricted'] = le.transform(test['end_turn_restricted'])"
      ],
      "metadata": {
        "id": "36wQs7PEfjAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링 사용 제외 칼럼 "
      ],
      "metadata": {
        "id": "VsCa6EsjfkKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['start_node_name', 'end_node_name', 'date', 'base_date'], axis = 1, inplace = True)\n",
        "test.drop(['start_node_name', 'end_node_name', 'date', 'base_date'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "c8skoE4afmY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## External Data"
      ],
      "metadata": {
        "id": "7cxFfHVpaTN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "공공 데이터 포럼 (2022년 8월 이전)\n",
        "\n",
        "* 무인교통단속카메라\n",
        "* 전국초중등학교기본정보\n",
        "* 어린이보호구역\n",
        "* 제주시 주차장 정보\n",
        "* 서귀포시 주차장 정보"
      ],
      "metadata": {
        "id": "h0hpwLCvaXVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPS 값"
      ],
      "metadata": {
        "id": "VzKon-5cakfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gps_comb = train[['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude']].drop_duplicates()"
      ],
      "metadata": {
        "id": "mtRXL2zZaUt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 무인 단속 카메라"
      ],
      "metadata": {
        "id": "HFAdpz_8bthv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cctv = pd.read_csv('경찰청_제주특별자치도경찰청_무인교통단속카메라_20220616.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "dnTO-Fj3bwdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cctv = cctv.iloc[:, 3:-7].drop(['소재지도로명주소', '소재지지번주소'], axis = 1)"
      ],
      "metadata": {
        "id": "o6gWGo9KbzOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전국 초중등학교 기본 정보"
      ],
      "metadata": {
        "id": "QRFkBoj_b0wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "school = pd.read_csv('초중등학교.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "EQ_VqwaJb3pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "school = school[(school['데이터기준일자'] <= '2022-07-31') & (school['시도교육청명'].str.contains('제주'))]"
      ],
      "metadata": {
        "id": "rh69yAlfb5Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 어린이 보호 구역"
      ],
      "metadata": {
        "id": "79Km88Zkb8Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "child = pd.read_csv('제주특별자치도_어린이보호구역_20220513.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "CUYva3mvb9b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제주시 주차장"
      ],
      "metadata": {
        "id": "vveTIxINb_Ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parking1 = pd.read_csv(\"제주특별자치도_제주시_주차장정보_20210818_1630391997093_77385.csv\", encoding = 'cp949')"
      ],
      "metadata": {
        "id": "S6TXVj2icBfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parking1.dropna(subset = ['위도', '경도'], inplace = True)"
      ],
      "metadata": {
        "id": "TPSpseKWcDIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###서귀포시 주차장"
      ],
      "metadata": {
        "id": "5exlyQbvcEf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parking2 = pd.read_csv(\"제주특별자치도_서귀포시_주차장정보_20220425_1650966840250_33855.csv\", encoding = 'cp949')"
      ],
      "metadata": {
        "id": "ep1nmUQgcGbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 거리 계산"
      ],
      "metadata": {
        "id": "mqAbVKpccKbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_dist(x1, y1, x2, y2, a, b):\n",
        "    \n",
        "    area = abs((x1 - a) * (y2 - b) - (y1 - b) * (x2 - a))\n",
        "    AB = ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n",
        "    distance = area / AB\n",
        "    \n",
        "    return distance"
      ],
      "metadata": {
        "id": "7aACiV4WcLiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 데이터의 도로와 각 시설 및 구역의 위경도 좌표의 거리(위경도 좌표상 거리)가 0.0005이내일 경우 count +\n",
        "\n"
      ],
      "metadata": {
        "id": "9aqa3-UGcTEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_node_cnt(gps_values, infra_values) :\n",
        "    \n",
        "    cnt = []\n",
        "\n",
        "    for y1, x1, y2, x2 in gps_values.values :\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        for a, b in infra_values.values :\n",
        "\n",
        "            dist = cal_dist(x1, y1, x2, y2, a, b)\n",
        "\n",
        "            if dist < 0.0005 :\n",
        "                i += 1\n",
        "\n",
        "            else :\n",
        "                pass\n",
        "        cnt.append(i)\n",
        "    return cnt"
      ],
      "metadata": {
        "id": "lLqDHGHWcUUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cctv_cnt = get_node_cnt(gps_comb, cctv[['경도', '위도']])\n",
        "school_cnt = get_node_cnt(gps_comb, school[['경도', '위도']])\n",
        "child_cnt = get_node_cnt(gps_comb, child[['경도', '위도']])\n",
        "parking1_cnt = get_node_cnt(gps_comb, parking1[['경도', '위도']])\n",
        "parking2_cnt = get_node_cnt(gps_comb, parking2[['경도', '위도']])\n",
        "parking_cnt = list(np.array(parking1_cnt) + np.array(parking2_cnt))"
      ],
      "metadata": {
        "id": "iIYEnOX9cW9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gps_comb['CCTV_cnt'] = cctv_cnt\n",
        "gps_comb['school_cnt'] = school_cnt\n",
        "gps_comb['child_cnt'] = child_cnt\n",
        "gps_comb['parking_cnt'] = parking_cnt"
      ],
      "metadata": {
        "id": "D1G9qABKcefM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fil NaN"
      ],
      "metadata": {
        "id": "3yFHwTeEc6Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.merge(train, gps_comb, how = 'left')\n",
        "test = pd.merge(test, gps_comb, how = 'left').fillna(0)"
      ],
      "metadata": {
        "id": "CwoOCEz6c7ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제주 공항까지 거리 (Km)"
      ],
      "metadata": {
        "id": "6_toZ73kdAA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train과 test의 시작 위경도 좌표와 제주 공항 위경도 좌표까지의 거리(km)"
      ],
      "metadata": {
        "id": "DxuVXu0rdN7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeju_air = 33.506683, 126.493177"
      ],
      "metadata": {
        "id": "yP77YbexdL0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['j_a_dist'] = [haversine((v[0], v[1]), jeju_air, unit = 'km') for v in train[['start_latitude', 'start_longitude']].values]\n",
        "test['j_a_dist'] = [haversine((v[0], v[1]), jeju_air, unit = 'km') for v in test[['start_latitude', 'start_longitude']].values]"
      ],
      "metadata": {
        "id": "SaQPGKb4dQzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 한라산까지 거리 (Km)"
      ],
      "metadata": {
        "id": "LPHDSjttdR3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train과 test의 시작 위경도 좌표와 한라산 위경도 좌표까지의 거리(km)"
      ],
      "metadata": {
        "id": "-dtmQH5PdWAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hanla = 33.36168194, 126.5291548"
      ],
      "metadata": {
        "id": "YiIdJBRcdUmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['h_a_dist'] = [haversine((v[0], v[1]), hanla, unit = 'km') for v in train[['start_latitude', 'start_longitude']].values]\n",
        "test['h_a_dist'] = [haversine((v[0], v[1]), hanla, unit = 'km') for v in test[['start_latitude', 'start_longitude']].values]"
      ],
      "metadata": {
        "id": "XYgyp6I-dbaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "woF7c_JUfsf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* lane_count를 1, 2, 3으로 나누어 모델링\n",
        "* LGBM, XGBoost는 optuna로 파라미터 튜닝"
      ],
      "metadata": {
        "id": "k6ZRyMaBfv5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split X / y"
      ],
      "metadata": {
        "id": "IOVd5bqDgksF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(['target'], axis = 1)\n",
        "y = train.target\n",
        "\n",
        "target = test[X.columns]"
      ],
      "metadata": {
        "id": "e2ipadEKfttf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StratifiedKFold"
      ],
      "metadata": {
        "id": "qF619_Grgr15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits = 10, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "LNm0F6ZJgt-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = X[X['lane_count'] == 1].drop(['lane_count'], axis = 1)\n",
        "X2 = X[X['lane_count'] == 2].drop(['lane_count'], axis = 1)\n",
        "X3 = X[X['lane_count'] == 3].drop(['lane_count'], axis = 1)"
      ],
      "metadata": {
        "id": "KG6c_ROXgv-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = y[X1.index]\n",
        "y2 = y[X2.index]\n",
        "y3 = y[X3.index]"
      ],
      "metadata": {
        "id": "P23-E30agx-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standard1 = X1['day_of_week']\n",
        "standard2 = X2['day_of_week']\n",
        "standard3 = X3['day_of_week']"
      ],
      "metadata": {
        "id": "d19wp26igya4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = test[X.columns]"
      ],
      "metadata": {
        "id": "yqZGib93g0k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target1 = target.loc[target['lane_count'] == 1, X1.columns]\n",
        "target2 = target.loc[target['lane_count'] == 2, X2.columns]\n",
        "target3 = target.loc[target['lane_count'] == 3, X3.columns]"
      ],
      "metadata": {
        "id": "WErEBAqEg2sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Catboost"
      ],
      "metadata": {
        "id": "ymu31HmFg3hn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catboost 1"
      ],
      "metadata": {
        "id": "kzBqn5jUhaiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb_pred1 = np.zeros(target1.shape[0])\n",
        "i = 0\n",
        "cb_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X1, standard1):\n",
        "    \n",
        "    tr_x, tr_y = X1.iloc[tr_idx], y1.iloc[tr_idx]\n",
        "    val_x, val_y = X1.iloc[val_idx], y1.iloc[val_idx]\n",
        "\n",
        "    cb = CatBoostRegressor(max_depth = 8, learning_rate = 0.033, use_best_model = True, iterations = 10000, eval_metric = 'MAE')\n",
        "\n",
        "    cb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 5, verbose = 2500)\n",
        "\n",
        "    val_pred = cb.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    cb_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = cb.predict(target1) / skf.n_splits\n",
        "    cb_pred1 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(cb_mae)}\")"
      ],
      "metadata": {
        "id": "nO1g70nmg4Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./cb_pred1', cb_pred1)"
      ],
      "metadata": {
        "id": "jFX0XxzXg9cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catboost 2"
      ],
      "metadata": {
        "id": "RQnJrm99hc1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb_pred2 = np.zeros(target2.shape[0])\n",
        "i = 0\n",
        "cb_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X2, standard2):\n",
        "    \n",
        "    tr_x, tr_y = X2.iloc[tr_idx], y2.iloc[tr_idx]\n",
        "    val_x, val_y = X2.iloc[val_idx], y2.iloc[val_idx]\n",
        "\n",
        "    cb = CatBoostRegressor(max_depth = 8, learning_rate = 0.033, use_best_model = True, iterations = 10000, eval_metric = 'MAE')\n",
        "\n",
        "    cb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 5, verbose = 2500)\n",
        "\n",
        "    val_pred = cb.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    cb_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = cb.predict(target2) / skf.n_splits\n",
        "    cb_pred2 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(cb_mae)}\")"
      ],
      "metadata": {
        "id": "rXylfs9fhADc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./cb_pred2', cb_pred2)"
      ],
      "metadata": {
        "id": "UxKr55eFhAun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catboost 3"
      ],
      "metadata": {
        "id": "ImxNiOSshef-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb_pred3 = np.zeros(target3.shape[0])\n",
        "i = 0\n",
        "cb_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X3, standard3):\n",
        "    \n",
        "    tr_x, tr_y = X3.iloc[tr_idx], y3.iloc[tr_idx]\n",
        "    val_x, val_y = X3.iloc[val_idx], y3.iloc[val_idx]\n",
        "\n",
        "    cb = CatBoostRegressor(max_depth = 8, learning_rate = 0.033, use_best_model = True, iterations = 10000, eval_metric = 'MAE')\n",
        "\n",
        "    cb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 8, verbose = 2500)\n",
        "\n",
        "    val_pred = cb.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    cb_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = cb.predict(target3) / skf.n_splits\n",
        "    cb_pred3 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(cb_mae)}\")"
      ],
      "metadata": {
        "id": "LJUbT0EvhCVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./cb_pred3', cb_pred3)"
      ],
      "metadata": {
        "id": "toPRCTt1hFfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LGBMRegressor"
      ],
      "metadata": {
        "id": "yjOf-m7ihHpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LGBMRegressor 1"
      ],
      "metadata": {
        "id": "n-7NFA6yhhCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_param1 = {\n",
        "    'objective' : 'regression',\n",
        "    'device' : 'gpu',\n",
        "    'metric' : 'mae',\n",
        "    'verbose' : -1,\n",
        "    'random_state' : 42,\n",
        "    'n_estimators' : 1468,\n",
        "    'learning_rate' : 0.033,\n",
        "    'max_depth' : 29,\n",
        "    'min_child_samples' : 16,\n",
        "    'subsample' : 0.7,\n",
        "    'colsample_bytree' : 0.9,\n",
        "    'num_leaves' : 979\n",
        "}"
      ],
      "metadata": {
        "id": "bC1ydhtqhLn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_pred1 = np.zeros(target1.shape[0])\n",
        "i = 0\n",
        "lgbm_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X1, standard1):\n",
        "    \n",
        "    tr_x, tr_y = X1.iloc[tr_idx], y1.iloc[tr_idx]\n",
        "    val_x, val_y = X1.iloc[val_idx], y1.iloc[val_idx]\n",
        "\n",
        "    lgbm = LGBMRegressor(**lgbm_param1)\n",
        "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 5, verbose = 2500)\n",
        "\n",
        "    val_pred = lgbm.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    lgbm_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = lgbm.predict(target1) / skf.n_splits\n",
        "    lgbm_pred1 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(lgbm_mae)}\")"
      ],
      "metadata": {
        "id": "K6uWDUpqhNH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./lgbm_pred1', lgbm_pred1)"
      ],
      "metadata": {
        "id": "ueDuw4-thXWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LGBMRegressor 2"
      ],
      "metadata": {
        "id": "IcjAl9Eqh05M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_param2 = {\n",
        "    'objective' : 'regression',\n",
        "    'device' : 'gpu',\n",
        "    'metric' : 'mae',\n",
        "    'verbose' : -1,\n",
        "    'random_state' : 42,\n",
        "    'n_estimators' : 1498,\n",
        "    'learning_rate' : 0.043,\n",
        "    'max_depth' : 21,\n",
        "    'min_child_samples' : 23,\n",
        "    'subsample' : 1.0,\n",
        "    'colsample_bytree' : 1.0,\n",
        "    'num_leaves' : 662\n",
        "}"
      ],
      "metadata": {
        "id": "xwd-qCRMhZEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_pred2 = np.zeros(target2.shape[0])\n",
        "i = 0\n",
        "lgbm_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X2, standard2):\n",
        "    \n",
        "    tr_x, tr_y = X2.iloc[tr_idx], y2.iloc[tr_idx]\n",
        "    val_x, val_y = X2.iloc[val_idx], y2.iloc[val_idx]\n",
        "\n",
        "    lgbm = LGBMRegressor(**lgbm_param2)\n",
        "\n",
        "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 5, verbose = 2500)\n",
        "\n",
        "    val_pred = lgbm.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    lgbm_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = lgbm.predict(target2) / skf.n_splits\n",
        "    lgbm_pred2 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(lgbm_mae)}\")"
      ],
      "metadata": {
        "id": "RGoiT4l5h-q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./lgbm_pred2', lgbm_pred2)"
      ],
      "metadata": {
        "id": "bjc2XS-JiCOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LGBMRegressor 3"
      ],
      "metadata": {
        "id": "AXKDbaULh1kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_param3 = {\n",
        "    'objective' : 'regression',\n",
        "    'device' : 'gpu',\n",
        "    'metric' : 'mae',\n",
        "    'verbose' : -1,\n",
        "    'random_state' : 42,\n",
        "    'n_estimators' : 627,\n",
        "    'learning_rate' : 0.047,\n",
        "    'max_depth' : 23,\n",
        "    'min_child_samples' : 28,\n",
        "    'subsample' : 0.6,\n",
        "    'colsample_bytree' : 1.0,\n",
        "    'num_leaves' : 819\n",
        "}"
      ],
      "metadata": {
        "id": "t8zzO60wh2K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "lgbm_pred3 = np.zeros(target3.shape[0])\n",
        "i = 0\n",
        "lgbm_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X3, standard3):\n",
        "    \n",
        "    tr_x, tr_y = X3.iloc[tr_idx], y3.iloc[tr_idx]\n",
        "    val_x, val_y = X3.iloc[val_idx], y3.iloc[val_idx]\n",
        "\n",
        "    lgbm = LGBMRegressor(**lgbm_param3)\n",
        "\n",
        "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 8, verbose = 2500)\n",
        "\n",
        "    val_pred = lgbm.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    lgbm_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\\n\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = lgbm.predict(target3) / skf.n_splits\n",
        "    lgbm_pred3 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(lgbm_mae)}\")"
      ],
      "metadata": {
        "id": "BOdIR3_liEFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./lgbm_pred3', lgbm_pred3)"
      ],
      "metadata": {
        "id": "SEdmL6mDiGaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBboost"
      ],
      "metadata": {
        "id": "pZnyA__3iHpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBboost 1"
      ],
      "metadata": {
        "id": "rJgCz8YgiVk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_param1 = {\n",
        "    'objective' : 'reg:squarederror',\n",
        "    'n_estimators' : 574,\n",
        "    'learning_rate' : 0.031000000000000003,\n",
        "    'nthread' : -1,\n",
        "    'max_depth' : 15,\n",
        "    'min_child_weight' : 7,\n",
        "    'gamma' : 0.35000000000000003,\n",
        "    'colsample_bytree' : 0.8,\n",
        "    'lambda' : 0.8500000000000001,\n",
        "    'alpha' : 0.0,\n",
        "    'subsample' : 1.0,\n",
        "    'tree_method' : 'gpu_hist',\n",
        "    'predictor' : 'gpu_predictor'\n",
        "}"
      ],
      "metadata": {
        "id": "0UuiNEHdiJec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_pred1 = np.zeros(target1.shape[0])\n",
        "i = 0\n",
        "xgb_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X1, standard1):\n",
        "    \n",
        "    tr_x, tr_y = X1.iloc[tr_idx], y1.iloc[tr_idx]\n",
        "    val_x, val_y = X1.iloc[val_idx], y1.iloc[val_idx]\n",
        "\n",
        "    xgb = XGBRegressor(**xgb_param1)\n",
        "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 8, verbose = 1000, eval_metric = 'mae')\n",
        "\n",
        "    val_pred = xgb.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    xgb_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = xgb.predict(target1) / skf.n_splits\n",
        "    xgb_pred1 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(xgb_mae)}\")"
      ],
      "metadata": {
        "id": "JBrr9daYid4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./xgb_pred1', xgb_pred1)"
      ],
      "metadata": {
        "id": "R_cpJ1quif9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBboost 2"
      ],
      "metadata": {
        "id": "5qaPMwOViYWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_param2 = {\n",
        "    'objective' : 'reg:squarederror',\n",
        "    'n_estimators' : 999,\n",
        "    'learning_rate' : 0.047,\n",
        "    'nthread' : -1,\n",
        "    'max_depth' : 16,\n",
        "    'min_child_weight' : 10,\n",
        "    'gamma' : 0.8500000000000001,\n",
        "    'colsample_bytree' : 0.7,\n",
        "    'lambda' : 0.65,\n",
        "    'alpha' : 0.45,\n",
        "    'subsample' : 1.0,\n",
        "    'tree_method' : 'gpu_hist',\n",
        "    'predictor' : 'gpu_predictor'\n",
        "}"
      ],
      "metadata": {
        "id": "1zNekPnRiYw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_pred2 = np.zeros(target2.shape[0])\n",
        "i = 0\n",
        "xgb_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X2, standard2):\n",
        "    \n",
        "    tr_x, tr_y = X2.iloc[tr_idx], y2.iloc[tr_idx]\n",
        "    val_x, val_y = X2.iloc[val_idx], y2.iloc[val_idx]\n",
        "\n",
        "    xgb = XGBRegressor(**xgb_param2)\n",
        "    xgb.fit(tr_x, tr_y, eval_set=[(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 8, verbose = 1000, eval_metric = 'mae')\n",
        "\n",
        "    val_pred = xgb.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    xgb_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = xgb.predict(target2) / skf.n_splits\n",
        "    xgb_pred2 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(xgb_mae)}\")"
      ],
      "metadata": {
        "id": "qz8PehtIiiXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./xgb_pred2', xgb_pred2)"
      ],
      "metadata": {
        "id": "NGluQoXsikPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBboost 3"
      ],
      "metadata": {
        "id": "WCThDh4yiZOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_param3 = {\n",
        "    'objective' : 'reg:squarederror',\n",
        "    'n_estimators' : 310,\n",
        "    'learning_rate' : 0.031000000000000003,\n",
        "    'nthread' : -1,\n",
        "    'max_depth' : 14,\n",
        "    'min_child_weight' : 29,\n",
        "    'gamma' : 0.8,\n",
        "    'colsample_bytree' : 0.8,\n",
        "    'lambda' : 0.6000000000000001,\n",
        "    'alpha' : 0.35000000000000003,\n",
        "    'subsample' : 1.0,\n",
        "    'tree_method' : 'gpu_hist',\n",
        "    'predictor' : 'gpu_predictor'\n",
        "}"
      ],
      "metadata": {
        "id": "e_rucxB6iZoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_pred3 = np.zeros(target3.shape[0])\n",
        "i = 0\n",
        "xgb_mae = []\n",
        "\n",
        "for tr_idx, val_idx in skf.split(X3, standard3):\n",
        "    \n",
        "    tr_x, tr_y = X3.iloc[tr_idx], y3.iloc[tr_idx]\n",
        "    val_x, val_y = X3.iloc[val_idx], y3.iloc[val_idx]\n",
        "\n",
        "    xgb = XGBRegressor(**xgb_param3)\n",
        "    xgb.fit(tr_x, tr_y, eval_set=[(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 8, verbose = 1000, eval_metric = 'mae')\n",
        "\n",
        "    val_pred = xgb.predict(val_x).astype(int)\n",
        "    fold_mae = mean_absolute_error(val_y, val_pred)\n",
        "    xgb_mae.append(fold_mae)\n",
        "    print(f\"{i + 1} Fold MAE = {fold_mae}\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    fold_pred = xgb.predict(target3) / skf.n_splits\n",
        "    xgb_pred3 += fold_pred\n",
        "\n",
        "print(f\"\\nAVG of MAE = {np.mean(xgb_mae)}\")"
      ],
      "metadata": {
        "id": "kUioadwrinJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./xgb_pred3', xgb_pred3)"
      ],
      "metadata": {
        "id": "n2XbLPYUipcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "JC-M9LpuipxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "Et3K83FJiqjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ],
      "metadata": {
        "id": "pIJ2okcBiwRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### XGBoost\n",
        "xgb_pred1 = np.load('./xgb_pred1.npy')\n",
        "xgb_pred2 = np.load('./xgb_pred2.npy')\n",
        "xgb_pred3 = np.load('./xgb_pred3.npy')\n",
        "\n",
        "### LGBM\n",
        "lgbm_pred1 = np.load('./lgbm_pred1.npy')\n",
        "lgbm_pred2 = np.load('./lgbm_pred2.npy')\n",
        "lgbm_pred3 = np.load('./lgbm_pred3.npy')\n",
        "\n",
        "### CatBoost\n",
        "cb_pred1 = np.load('./cb_pred1.npy')\n",
        "cb_pred2 = np.load('./cb_pred2.npy')\n",
        "cb_pred3 = np.load('./cb_pred3.npy')"
      ],
      "metadata": {
        "id": "ZEZ_zwj4ixyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble - LGBM : XGBoost : CatBoost = 0.65 : 0.25 : 0.1\n",
        "submission.loc[target1.index, 'target'] = lgbm_pred1 * 0.65 + xgb_pred1 * 0.25 + cb_pred1 * 0.1\n",
        "submission.loc[target2.index, 'target'] = lgbm_pred2 * 0.65 + xgb_pred2 * 0.25 + cb_pred2 * 0.1\n",
        "submission.loc[target3.index, 'target'] = lgbm_pred3 * 0.65 + xgb_pred3 * 0.25 + cb_pred3 * 0.1"
      ],
      "metadata": {
        "id": "WxaPkeVfi1My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['target'] = round(submission['target'], 0)\n",
        "submission.to_csv('./lgbm_xgb_cb.csv', index = False)"
      ],
      "metadata": {
        "id": "JTQf-EzCi2Um"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}